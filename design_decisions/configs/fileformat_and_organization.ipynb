{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library for loading configs\n",
    "*Pydantic* is the clear winner, because:\n",
    "- it is flexible (supports multiple file formats, as well as overriding any config value using environment variables);\n",
    "- it ensures type-safety (and it has many inbuilt validators for things such as URLs or email addresses, so we don't have to reinvent the wheel to check these)\n",
    "\n",
    "# File format\n",
    "## JSON \n",
    "Advantages: \n",
    "- allows **nested** configs, which would be nice to have because that would allow us to:\n",
    "  - *organize* the configs in a better way, e.g. break up the configs for a single step by where they are needed (e.g., instantiating processor class vs for constructing run_args), which in turn may simplify that code.\n",
    "  - directly use lists and maps in config file, rather than having to add python code to construct this (e.g., convert a string to a list by splitting on commas and then stripping whitespaces, such as when defining depends_on) -> simplifies our code.\n",
    "- Easier to switch to Terraform template later, which has some other benefits (see below).\n",
    "\n",
    "## .env file\n",
    "Advantage: Easier for user to write, compared to JSON.\n",
    "\n",
    "## YAML\n",
    "Advantage: \n",
    "- easiest to read\n",
    "\n",
    "Disadvantage: \n",
    "- No straightforward way to achieve input type validation\n",
    "  - no native integration with pydantic (or any similar validation tool)\n",
    "  - While it is possible to [add a yaml reader for foydantic settings](https://docs.pydantic.dev/latest/concepts/pydantic_settings/#adding-sources), this is more complicated (and may have to change if pydantic changes internal implementations, which apparently happened recently). \n",
    "  - Thus, the best approach seems to be to simply separate loading of the yaml file, and then convert it to JSON. It remains to be seen whether this additional point of failure is worth the simplification of the configuration (in particular, have to test how meaningful error messages are if validation fails). \n",
    "\n",
    "## Decision\n",
    "I initially started with .env files because I thought I could work around the limitations of not having nesting. However, it currently looks like having access to nesting would allow for a substantial reduction in code complexity (especially for the step factories), so I'm planning to **switch to JSON** soon. \n",
    "In the medium term, try using **YAML file and convert to JSON**. It is hard to know beforehand whether this trade-off between config readability and having to add extra steps will be worth it; Will have to try it out once higher priority items are resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to break up into multiple files\n",
    "## By environment?\n",
    "For now, I'm breaking up the configs into a separate file for each environment. While there are some config values that could be shared across environments, this would introduce too much additional complexity. \n",
    "\n",
    "In the medium-term, the goal is to find a way to share config values that we want to be the same across environments, especially those that need to be the same in order to avoid unexpected differences in behavior â€“ e.g. step type (if it does come from a config - ideally we would avoid such potential sources of bugs altogether, such as by making the step type a property of a given processor).\n",
    "\n",
    "The main way to achieve this goal would be by splitting up the config into a **template** (which can directly set shared values) and use **parameters**  which are populated from a different file (one for each env). Note that the downside of this approach would be that it creates one more file across which configs are scattered, but hopefully this will be offset by the fact that the configs will be more organized.\n",
    "\n",
    "Todo: Look into ways how to implement this:\n",
    "- Simple way: Set shared values in a config file, and load an additional .env file that differs by environment\n",
    "  - Downsides: \n",
    "    - Doesn't allow parameter substitution (e.g., change prefix or postfix of a role name or bucket name) - have to set whole value.\n",
    "    - Doesn't easily allow nested config for anything that differs by environment (since we are bound by the limitations of .env files)\n",
    "- Use a Terraform template file \n",
    "  - Downsides:\n",
    "    - Have to see how usable that is for local development. (Worst case, we can resort to use pydantic's ability to override all the settings using environment variables for local development; though that too would become tedious if many of the configs are nested)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By pipeline step\n",
    "### Separate config for each step\n",
    "Advantage: Suuport the **Open-Closed principle**: makes the library easier to extend for users, because they can simply add a new file for a new step they want to add, but don't have to modify existing files.\n",
    "\n",
    "### Single config \n",
    "Advantage: slightly easier to load all configs at once, if we wanted to do that (don't have to traverse file paths, though that wouldn't be a big deal either).\n",
    "Downside: **users would have to modify existing config definition in order to extend the library, which severely limits the reusability of this library**, because it is impossible to foresee all necessary use cases (and even if he could, it would be infeasible to implement all these centrally).\n",
    "\n",
    "### Decision\n",
    "Clearly, we have to use a **separate config file for each step**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
