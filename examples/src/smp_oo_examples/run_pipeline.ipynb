{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 1.0.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/thomas-22/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "from sm_pipelines_oo.config_loader.implementations import MockConfigLoader\n",
    "from sm_pipelines_oo.pipeline import PipelineFacade, DevPipelineFacade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PROJECT_BUCKET = 'example-sm-pipelines-20231117141913829300000001'\n",
    "_DATA_PREFIX = 'examples/data/test_input_1.parquet'\n",
    "\n",
    "_shared_config_dict={\n",
    "    'project_name': 'test',\n",
    "    'project_version': '0',\n",
    "    'region': 'us-east-1',\n",
    "    'project_bucket_name': 'example-sm-pipelines-20231117141913829300000001',\n",
    "    'role_name': 'sagemaker_pipelines_role'\n",
    "}\n",
    "_fw_processor_config_dict = {\n",
    "    'step_name': 'preprocessing',\n",
    "    'step_factory_class': 'FrameworkProcessor',\n",
    "    'processor_init_config': {\n",
    "        'framework_version': '0.23-1',\n",
    "        'estimator_cls_name': 'SKLearn',\n",
    "        'instance_count': 1,\n",
    "        'instance_type': 'ml.m5.xlarge',\n",
    "    },\n",
    "    'processor_run_config': {\n",
    "        'code': 'preprocess.py',\n",
    "        'source_dir': 'worker_code/preprocess',\n",
    "        'input_files_s3paths': [\n",
    "            f's3://{_PROJECT_BUCKET}/{_DATA_PREFIX}',\n",
    "        ],\n",
    "        'output_files_s3paths': [],\n",
    "    },\n",
    "    'shared_config': _shared_config_dict\n",
    "}\n",
    "_mock_config_loader = MockConfigLoader(\n",
    "    shared_config_dict=_shared_config_dict,\n",
    "    step_configs_dicts=[_fw_processor_config_dict,]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S3Path('abc/key.json')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "from pydantic import field_validator, ValidationError\n",
    "from s3path import S3Path\n",
    "\n",
    "class _RunConfig(BaseSettings):\n",
    "    # todo: allow athena datasetdefinition instead\n",
    "    input_files_s3paths: list[str]  # todo: validate it's an s3 path\n",
    "\n",
    "    @field_validator('input_files_s3paths')\n",
    "    @classmethod\n",
    "    def parse_str_to_s3path(cls, path_list: list[str]) -> list[S3Path]:\n",
    "        return [S3Path(path_str) for path_str in path_list]\n",
    "\n",
    "good_class = _RunConfig(input_files_s3paths=['abc/key.json'])\n",
    "good_class.input_files_s3paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for ml\n",
      "INFO:botocore.tokens:SSO Token refresh succeeded\n",
      "/home/thomas-22/.cache/pypoetry/virtualenvs/sm-pipelines-oo-examples-yainlQgE-py3.10/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipeline = DevPipelineFacade(\n",
    "    env='dev',\n",
    "    # Use different configs for testing\n",
    "    config_loader=_mock_config_loader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.tokens:Loading cached SSO token for ml\n",
      "INFO:sagemaker.processing:Uploaded worker_code/preprocess to s3://sagemaker-us-east-1-338755209567/test-v0/code/c539bb7cbc8181b1d0f8b983c763d37f/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-338755209567/test-v0/code/bc2536a25d34e1ecae5238f42f4207c2/runproc.sh\n",
      "/home/thomas-22/.cache/pypoetry/virtualenvs/sm-pipelines-oo-examples-yainlQgE-py3.10/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "\u001b[32m2024-02-28 20:06:24.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msm_pipelines_oo.pipeline\u001b[0m:\u001b[36mexport_pipeline_definition_to_s3\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mUploaded pipeline definition to s3://example-sm-pipelines-20231117141913829300000001/pipeline_definitions/test-v0-definition.json\u001b[0m\n",
      "\n",
      "An error occurred (ValidationException) when calling the CreatePipeline operation: Pipeline names must be unique within an AWS account and region. Pipeline with name (test-v0) already exists.\n",
      "\u001b[32m2024-02-28 20:06:26.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msm_pipelines_oo.pipeline\u001b[0m:\u001b[36mupsert_pipeline\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mCreating pipeline failed. Trying to update it instead.\u001b[0m\n",
      "\u001b[32m2024-02-28 20:06:27.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msm_pipelines_oo.pipeline\u001b[0m:\u001b[36mupsert_pipeline\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1mPipeline updated successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline.create_and_start_pipeline_from_definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
