{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facade + Factory-Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 1.0.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imports and folder paths work\n",
    "# todo: Instead create python package and install locally\n",
    "import os, sys\n",
    "os.chdir(\n",
    "    f'{os.environ[\"HOME\"]}/repos/sagemaker-pipelines-abstraction/src'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/thomas-22/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from functools import cached_property\n",
    "from typing import Literal, Callable, TypeAlias, Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import TypeVar, Generic\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_settings import BaseSettings\n",
    "from loguru import logger\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import Step\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.workflow.steps import ConfigurableRetryStep, ProcessingStep\n",
    "from sm_pipelines_oo.shared_config_schema import Environment\n",
    "\n",
    "from sm_pipelines_oo.shared_config_schema import SharedConfig, Environment\n",
    "# from sm_pipelines_oo.steps.interfaces import StepFactoryInterface\n",
    "from sm_pipelines_oo.aws_connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.utils import load_pydantic_config_from_file\n",
    "from sm_pipelines_oo.aws_connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.aws_connector.implementation import AWSConnector, LocalAWSConnector, \\\n",
    "    create_aws_connector\n",
    "from sm_pipelines_oo.pipeline_wrapper import PipelineWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "# ==========\n",
    "\n",
    "class ProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    This class defines all the config values shared by any subtype of processing step.\n",
    "    \"\"\"\n",
    "    input_filename: str\n",
    "    output_train_filename: str\n",
    "    output_val_filename: str\n",
    "    output_test_filename: str\n",
    "    instance_type: str\n",
    "    instance_count: int\n",
    "    sklearn_framework_version: str\n",
    "    code_filename: str\n",
    "\n",
    "class FrameworkProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    This class defines all the config values that are specific to a FrameworkProcessor.\n",
    "    \"\"\"\n",
    "    # While it would be nice if we could set `estimator_cls=SKLearn`in the config file, we would\n",
    "    # have to use `eval()` to construct a python object from the string, which is a potential\n",
    "    # security vulnerability.)\n",
    "    estimator_cls: Literal['SKLearn'] = 'SKLearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic StepConfig FACADE\n",
    "# =========================\n",
    "\n",
    "# Each of the types must be a subclass of BaseSettings\n",
    "StepSpecificConfigType = TypeVar(\"StepSpecificConfigType\", bound=BaseSettings)\n",
    "AdditionalConfigType = TypeVar(\"AdditionalConfigType\", bound=BaseSettings)\n",
    "\n",
    "@dataclass\n",
    "class StepConfigFacade(\n",
    "    Generic[StepSpecificConfigType, AdditionalConfigType]\n",
    "):\n",
    "    step_name: str\n",
    "    steptype_specific_configs: StepSpecificConfigType\n",
    "    additional_configs: AdditionalConfigType\n",
    "\n",
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    FrameworkProcessingConfig,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config FACTORY\n",
    "# ===============\n",
    "class ConfigFactoryInterface:\n",
    "    \"\"\"Abstraction layer that allows accessing both shared config and step configs.\"\"\"\n",
    "    @abstractmethod\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> StepConfigFacade:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example configs\n",
    "fw_proc_configs = FrameworkProcessingConfigFacade(\n",
    "    step_name='pre_processing',\n",
    "    steptype_specific_configs=ProcessingConfig(\n",
    "        input_filename='input.parquet',\n",
    "        output_train_filename='output_train.parquet',\n",
    "        output_val_filename='output_val.parquet',\n",
    "        output_test_filename='output_test.parquet',\n",
    "        instance_type='local',\n",
    "        instance_count=1,\n",
    "        sklearn_framework_version='0.23-1',\n",
    "        code_filename='pre_processing.py',\n",
    "    ),\n",
    "    additional_configs=FrameworkProcessingConfig(\n",
    "        estimator_cls='SKLearn',\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "class MockFWPConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    This class is used to create a mock config for testing purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> FrameworkProcessingConfigFacade:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        if step_name == 'processing':\n",
    "            return fw_proc_configs\n",
    "        else:\n",
    "            raise NotImplementedError(f'No config defined for step {step_name}')\n",
    "\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        return SharedConfig(\n",
    "            project_name=\"test\",\n",
    "            project_version='v0.0',\n",
    "            region='us-east-1',\n",
    "            role_name='test_role',\n",
    "            project_bucket_name='test-bucket',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    The pipeline fa√ßade will usually use this class to load configs. Only explicitly specify a\n",
    "    different class implementing the same interface for testing purposes (e.g., to directly define\n",
    "    config rather than reading from file).\n",
    "    \"\"\"\n",
    "    # todo: Put reading of configs from file, etc, here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>26: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[Any, Any]\"\u001b[m has no attribute \u001b[m\u001b[1m\"input_s3_dir\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>34: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[Any, Any]\"\u001b[m has no attribute \u001b[m\u001b[1m\"output_s3_dir\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "StepType: TypeAlias = Literal['processing', 'training', 'model', 'evaluation']\n",
    "\n",
    "class PathFactory:\n",
    "    # todo: use general step config, once stable.\n",
    "    # todo: Add interface (or rename to distinguish from actual factory patterns)\n",
    "    def __init__(self, step_config_facade: StepConfigFacade, shared_config: SharedConfig):\n",
    "        self._step_config_facade = step_config_facade\n",
    "        self._shared_config = shared_config\n",
    "\n",
    "    # S3 Folder Paths\n",
    "    # ===============\n",
    "\n",
    "    @cached_property\n",
    "    def _default_s3_data_folder(self) -> str:\n",
    "        default_bucket_name = self._shared_config.project_bucket_name\n",
    "        project_version = self._shared_config.project_version\n",
    "        step_name = self._step_config_facade.step_name\n",
    "        return f\"s3://{default_bucket_name}/{project_version}/{step_name}\"\n",
    "\n",
    "    @cached_property\n",
    "    def s3_input_folder(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns custom s3 folder with input data, if provided. Otherwise returns default s3 input\n",
    "        folder.\n",
    "        \"\"\"\n",
    "        custom_s3_folder: str | None = self._step_config_facade.input_s3_dir\n",
    "        default_s3_folder = f\"{self._default_s3_data_folder}/input\"\n",
    "        return  custom_s3_folder or default_s3_folder\n",
    "\n",
    "    @cached_property\n",
    "    def s3_output_folder(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns custom s3 folder with output data, if provided. Otherwise returns default s3 output\n",
    "        folder.\n",
    "        \"\"\"\n",
    "        custom_s3_folder: str | None = self._step_config_facade.output_s3_dir\n",
    "        default_s3_folder = f'{self._default_s3_data_folder}/output'\n",
    "        return  custom_s3_folder or default_s3_folder\n",
    "\n",
    "    # Local Folder Paths\n",
    "    # =================\n",
    "\n",
    "    def get_local_folderpath(self, step_type: StepType) -> str:\n",
    "        # Note that `/opt/ml/${STEP_TYPE}/` is *required* by Sagemaker.\n",
    "        # todo: Use more precise type annotation? (Create type for StepType)\n",
    "        step_name: str = self._step_config_facade.step_name\n",
    "        return f'/opt/ml/{step_type}/{step_name}'\n",
    "\n",
    "    @property\n",
    "    def source_dir(self) -> str:\n",
    "        # Hard-code source_directory name to simplify configs.\n",
    "        return f\"code/{self._step_config_facade.step_name}/\"\n",
    "\n",
    "    @property\n",
    "    def step_code_file(self) -> str:\n",
    "        # Hard-code name of step's code file to simplify configs.\n",
    "        return f\"{self._step_config_facade.step_name}.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *General* step FACTORY INTERFACE\n",
    "# ===============================\n",
    "\n",
    "class StepFactoryInterface(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        step_config_facade: StepConfigFacade,\n",
    "        path_factory: PathFactory, # todo: create interface\n",
    "        aws_connector: AWSConnectorInterface,\n",
    "\n",
    "    ) -> ConfigurableRetryStep:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_name(self) -> str:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_type(self) -> StepType:\n",
    "        \"\"\"This tells us where Sagemaker stores local copy of data, e.g., /opt/ml/processing/.\"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class ProcessingStepFactoryInterface(StepFactoryInterface):\n",
    "    \"\"\"\n",
    "    This subclass is distinguished only by more specific return type for step (and step_type name).\n",
    "    .\"\"\"\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        step_config_facade: StepConfigFacade,\n",
    "        path_factory: PathFactory, # todo: create interface\n",
    "        aws_connector: AWSConnectorInterface,\n",
    "    ) -> ProcessingStep:\n",
    "         ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_type(self) -> Literal['processing']:\n",
    "        ...\n",
    "\n",
    "\n",
    "class FrameworkProcessorFactory(ProcessingStepFactoryInterface):\n",
    "    # todo: Check if there is an inbuilt type for fwp-step.\n",
    "    @property\n",
    "    def step_type(self) -> Literal['processing']:\n",
    "        return 'processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Run Args\n",
    "# ========\n",
    "class ProcessorRunArgs(TypedDict):\n",
    "    inputs: list[ProcessingInput]\n",
    "    outputs: list[ProcessingOutput]\n",
    "    arguments: list[str] | None\n",
    "\n",
    "class FrameworkProcessorRunArgs(ProcessorRunArgs):\n",
    "    # Additional args for FrameworkProcessor:\n",
    "    source_dir: str\n",
    "    code: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>71: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[ProcessingConfig, FrameworkProcessingConfig]\"\u001b[m has no attribute \u001b[m\u001b[1m\"input_s3_dir\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>79: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[ProcessingConfig, FrameworkProcessingConfig]\"\u001b[m has no attribute \u001b[m\u001b[1m\"s3_output_folder\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>84: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[ProcessingConfig, FrameworkProcessingConfig]\"\u001b[m has no attribute \u001b[m\u001b[1m\"s3_output_folder\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>89: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepConfigFacade[ProcessingConfig, FrameworkProcessingConfig]\"\u001b[m has no attribute \u001b[m\u001b[1m\"s3_output_folder\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>92: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"_step_config_facade\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>119: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"ProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"output_data\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>126: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"ProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"output_data\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>127: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"ProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"output_data\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>133: \u001b[1m\u001b[31merror:\u001b[m Cannot instantiate abstract class \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m with abstract attribute \u001b[m\u001b[1m\"step_type\"\u001b[m  \u001b[m\u001b[33m[abstract]\u001b[m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PipelineSession, LocalPipelineSession\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step Factory IMPLEMENTATION\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ===========================\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFrameworkProcessingStepFactory\u001b[39;00m(ProcessingStepFactoryInterface):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    shared config etc will be passed during create_step().\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     14\u001b[0m         step_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     15\u001b[0m     ):\n",
      "Cell \u001b[0;32mIn[12], line 47\u001b[0m, in \u001b[0;36mFrameworkProcessingStepFactory\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_name\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# todo: Generalize types to other processors\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_processor\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     44\u001b[0m     step_config_facade: FrameworkProcessingConfigFacade,\n\u001b[1;32m     45\u001b[0m     sagemaker_session: PipelineSession \u001b[38;5;241m|\u001b[39m Session \u001b[38;5;241m|\u001b[39m LocalPipelineSession,\n\u001b[1;32m     46\u001b[0m     role_arn: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m---> 47\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mProcessor\u001b[49m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Instantiate processor.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Get processor class from classname string in config file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Processor' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import Session\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "\n",
    "# Step Factory IMPLEMENTATION\n",
    "# ===========================\n",
    "\n",
    "class FrameworkProcessingStepFactory(ProcessingStepFactoryInterface):\n",
    "    \"\"\"\n",
    "    shared config etc will be passed during create_step().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        step_name: str,\n",
    "    ):\n",
    "        self._step_name = step_name\n",
    "\n",
    "        # This determines how to construct the estimator object from the string in the config file, avoiding the\n",
    "        # use of `eval`, which is a potential security vulnerability.\n",
    "        self._str_to_cls_mapping: dict[str, Any] = {  # todo:  find supertype\n",
    "            'SKLearn': SKLearn,\n",
    "        }\n",
    "\n",
    "    def support_additional_estimators(self, additional_estimator_mapping: dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Allow user to add additional estimators (following the open-closed principle).\n",
    "\n",
    "        Note: We don't use composition, because passing this mapping to constructor would violate\n",
    "        the shared interface for StepFactory's constructor. Instead, we add an addiitonal method\n",
    "        to allow updating the mapping.\n",
    "        \"\"\"\n",
    "        self._str_to_cls_mapping.update(additional_estimator_mapping)\n",
    "\n",
    "    @property\n",
    "    def step_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Facade calls this method before create_step(), so it can retrieve the right config first.\n",
    "        \"\"\"\n",
    "        return self._step_name\n",
    "\n",
    "    # todo: Generalize types to other processors\n",
    "    def _processor(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "        sagemaker_session: PipelineSession | Session | LocalPipelineSession,\n",
    "        role_arn: str,\n",
    "    ) -> Processor:  # type: ignore\n",
    "        \"\"\"Instantiate processor.\"\"\"\n",
    "\n",
    "        # Get processor class from classname string in config file\n",
    "        _processor_cls_name: str = step_config_facade.additional_configs.estimator_cls\n",
    "        processor_cls = self._str_to_cls_mapping[_processor_cls_name]\n",
    "        return processor_cls(\n",
    "            framework_version=step_config_facade.steptype_specific_configs.sklearn_framework_version,\n",
    "            instance_type=step_config_facade.steptype_specific_configs.instance_type,\n",
    "            instance_count=step_config_facade.steptype_specific_configs.instance_count,\n",
    "            base_job_name=step_config_facade.step_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            role=role_arn,\n",
    "            # **self._processor_extra_kwargs,\n",
    "        )  # type: ignore\n",
    "\n",
    "    def _get_processor_run_args(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "    ) -> FrameworkProcessorRunArgs:\n",
    "\n",
    "        skl_run_args = FrameworkProcessorRunArgs(\n",
    "            inputs = [\n",
    "                ProcessingInput(\n",
    "                    source=step_config_facade.input_s3_dir,\n",
    "                    destination=f'/opt/ml/{self.step_type}/{step_config_facade.step_name}/input/'\n",
    "                ),\n",
    "            ],\n",
    "            outputs = [\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"train\",\n",
    "                    source=f'/opt/ml/{self.step_type}/{step_config_facade.step_name}/train',\n",
    "                    destination=f\"{step_config_facade.s3_output_folder}/train\",\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"validation\",\n",
    "                    source=f\"/opt/ml/{self.step_type}/{step_config_facade.step_name}/validation\",\n",
    "                    destination=f\"{step_config_facade.s3_output_folder}/validation\",\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"test\",\n",
    "                    source=f\"/opt/ml/{self.step_type}/{step_config_facade.step_name}/test\",\n",
    "                    destination=f\"{step_config_facade.s3_output_folder}/test\",\n",
    "                ),\n",
    "            ],\n",
    "            source_dir=f\"code/{_step_config_facade.step_name}/\",\n",
    "            code=f'{step_config_facade.step_name}.py', # Hard-code to avoid extra config value\n",
    "            arguments=None, # Todo: Decide whether this should come from configuration. May depend on type of step.\n",
    "        )\n",
    "        return skl_run_args\n",
    "\n",
    "    # todo: Add more specific return type (may have to create custom type, but check Sagemaker sdk code again)\n",
    "    def create_step(\n",
    "            self,\n",
    "            shared_config: SharedConfig,\n",
    "            step_config_facade: StepConfigFacade,\n",
    "            path_factory: PathFactory,\n",
    "            aws_connector: AWSConnectorInterface,\n",
    "        ) -> ProcessingStep:\n",
    "        # todo: think about how to create these here\n",
    "        step_config_facade = fw_proc_configs\n",
    "\n",
    "        return ProcessingStep(\n",
    "            name=step_config_facade.step_name,\n",
    "            processor=self._processor(\n",
    "                step_config_facade=step_config_facade,\n",
    "                sagemaker_session=aws_connector.sm_session,\n",
    "                role_arn=aws_connector.role_arn,\n",
    "            ),\n",
    "            inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=step_config_facade.steptype_specific_configs.input_filename,\n",
    "                    destination=step_config_facade.steptype_specific_configs.output_data,\n",
    "                    s3_data_type='S3Prefix',\n",
    "                    s3_input_mode='File',\n",
    "                )\n",
    "            ],\n",
    "            outputs=[\n",
    "                ProcessingOutput(\n",
    "                    source=step_config_facade.steptype_specific_configs.output_data,\n",
    "                    destination=step_config_facade.steptype_specific_configs.output_data,\n",
    "                    s3_upload_mode='EndOfJob',\n",
    "                )\n",
    "            ],\n",
    "            code=step_config_facade.steptype_specific_configs.code_filename,\n",
    "        )\n",
    "fw_proc_step_factory = FrameworkProcessingStepFactory(step_name='preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline facade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineFacade:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each step factory is instantiated with its step_name, thus identifying step_config\n",
    "        step_factories: list[StepFactoryInterface],\n",
    "        env: Environment,\n",
    "        config_factory: ConfigFactoryInterface | None,\n",
    "        path_factory: PathFactory,\n",
    "        estimator_name_to_class_mapping: dict[str, Any] | None = None,\n",
    "    ) -> None:\n",
    "        self._env: Environment = env\n",
    "        self._step_factories = step_factories\n",
    "        self._config_factory = config_factory\n",
    "        self._estimator_name_to_class_mapping = estimator_name_to_class_mapping\n",
    "        self._path_factory = path_factory\n",
    "\n",
    "        # Derived attributes\n",
    "        # ==================\n",
    "        # Note that we are using the config_factory *property*, which is always defined\n",
    "        self._shared_config: SharedConfig = self.config_factory.get_shared_config(env=self._env)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def estimator_name_to_class_mapping(self) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        This determines how to construct the estimator object from the string in the config file, avoiding the\n",
    "        use of `eval`, which is a potential security vulnerability.\n",
    "        \"\"\"\n",
    "        # Default mapping\n",
    "        if self._estimator_name_to_class_mapping is None:\n",
    "            return {'SKLearn': SKLearn} # todo: add more estimators\n",
    "\n",
    "        # Allow user to override default to specify additional estimator classes\n",
    "        else:\n",
    "            return self._estimator_name_to_class_mapping\n",
    "\n",
    "    @property\n",
    "    def config_factory(self) -> ConfigFactoryInterface:\n",
    "        # Generally, default is fine\n",
    "        if self._config_factory is None:\n",
    "            return DefaultConfigFactory()\n",
    "\n",
    "        # Allow user to pass a custom factory, e.g. a mock factory for testing.\n",
    "        else:\n",
    "            return self._config_factory\n",
    "\n",
    "    @cached_property\n",
    "    def _steps(self) -> list[Step]:\n",
    "        steps: list[Step] = []\n",
    "        for step_factory in self._step_factories:\n",
    "            step_configs: StepConfigFacade = self.config_factory.get_step_configs(\n",
    "                env=self._env,\n",
    "                step_name=step_factory.step_name,\n",
    "            )\n",
    "            step: Step = step_factory.create_step(\n",
    "                shared_config=self._shared_config,\n",
    "                step_configs=step_configs,\n",
    "                path_factory=self._path_factory,\n",
    "            )\n",
    "            steps.append(step)\n",
    "        return steps\n",
    "\n",
    "    @cached_property\n",
    "    def _aws_connector(self) -> AWSConnectorInterface:\n",
    "        \"\"\"\n",
    "        This code makes connector.implementation.create_aws_connector() redundant, except for use\n",
    "        outside of pipeline.\n",
    "        Todo: decide where to put code for the latter case.\n",
    "        \"\"\"\n",
    "        # todo: make this a factory, so we can move this logic out of facade?\n",
    "        if self._env == 'local':\n",
    "            return LocalAWSConnector()\n",
    "        else:\n",
    "            return AWSConnector(\n",
    "                environment=self._env,\n",
    "                # this error will resolve once we don't use SharedConfig from this notebook but\n",
    "                # library's AWSConnector.\n",
    "                shared_config=self._shared_config,  # type: ignore\n",
    "                run_as_pipeline=True\n",
    "            )\n",
    "\n",
    "    @cached_property\n",
    "    def _pipeline(self) -> Pipeline:\n",
    "        \"\"\"\n",
    "        We could make this a private  method and call it in __init__(), but this is shorter.\n",
    "        \"\"\"\n",
    "        pipeline_name = f'{self._shared_config.project_name}-{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "        pipeline = Pipeline(\n",
    "            name=pipeline_name,\n",
    "            steps=self._steps,\n",
    "            sagemaker_session=self._aws_connector.sm_session,\n",
    "        )\n",
    "        pipeline.create(role_arn=self._aws_connector.role_arn)\n",
    "        return pipeline\n",
    "\n",
    "    def run(self) -> None:\n",
    "        try:\n",
    "            logger.info(f\"Starting pipeline run for project {self._shared_config.project_name}\")\n",
    "            execution = self._pipeline.start()\n",
    "            execution.wait()\n",
    "            execution.list_steps()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= PipelineFacade(\n",
    "    step_factories=[fw_proc_step_factory],\n",
    "    env='local',\n",
    "    config_factory=MockFWPConfigFactory(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
