{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 1.0.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imports and folder paths work\n",
    "# todo: Instead create python package and install locally\n",
    "import os, sys\n",
    "os.chdir(\n",
    "    f'{os.environ[\"HOME\"]}/repos/sagemaker-pipelines-abstraction/src'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/thomas-22/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Generic, TypeVar\n",
    "\n",
    "import boto3\n",
    "from sagemaker.session import Session, get_execution_role\n",
    "from sagemaker.processing import Processor, FrameworkProcessor\n",
    "from sagemaker.base_predictor import Predictor\n",
    "from sagemaker.workflow.steps import ConfigurableRetryStep, ProcessingStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "from sm_pipelines_oo.shared_config_schema import SharedConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative 1: Make ProcessingStepFactoryInterface *generic* in ProcessorType \n",
    "**Problem: Different types of Processors require different run_args (and potentially different extra_kwargs), which is not possible using this architecture.**\n",
    "\n",
    "We could try to solve this by adding two more generic type variables, RunArgsType and ExtraKwargsType, but this would not only overly complicate things, but also we would have to rely on the caller to pass a matching set of these three types variables. To solve this, we could define a concrete interface in a single place for each matching set of type variables, but it's probably easier to simply use subclassing instead of generics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# *General* step factory interface\n",
    "# ==============================\n",
    "class StepFactoryInterface(ABC):\n",
    "    @abstractmethod\n",
    "    def create_step(self, shared_config) -> ConfigurableRetryStep:\n",
    "        ...\n",
    "\n",
    "\n",
    "# Factory interfaces for *specific* step types\n",
    "# =============================================\n",
    "ProcessorType = TypeVar(\"ProcessorType\", bound=Processor)\n",
    "\n",
    "class ProcessingStepFactoryInterface(StepFactoryInterface, Generic[ProcessorType]):\n",
    "    @abstractmethod\n",
    "    def create_step(self, shared_config) -> ProcessingStep:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def processor(self) -> ProcessorType:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_processor_run_args(self, shared_config: SharedConfig) -> dict:\n",
    "        # todo: improve return type\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_processor_extra_kwargs(self, shared_config: SharedConfig) -> dict:\n",
    "        # todo: improve return type\n",
    "        ...\n",
    "\n",
    "\n",
    "# Use\n",
    "# ====\n",
    "framework_processing_step_interface = ProcessingStepFactoryInterface[FrameworkProcessor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative 2: Define interface for ProcessorType, and implement for each Processortype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *General* step factory interface\n",
    "# ==============================\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "class BaseStepFactoryInterface(ABC):\n",
    "    @abstractmethod\n",
    "    def create_step(self, shared_config) -> ConfigurableRetryStep:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factory interfaces for *processing* step\n",
    "# =============================================\n",
    "\n",
    "class ProcessingStepFactoryInterface(BaseStepFactoryInterface):\n",
    "    @abstractmethod\n",
    "    def create_step(self, shared_config: SharedConfig) -> ProcessingStep:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def processor(self) -> Processor:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_processor_run_args(self, shared_config: SharedConfig) -> dict:\n",
    "        # todo: improve return type\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_processor_extra_kwargs(self, shared_config: SharedConfig) -> dict:\n",
    "        # todo: improve return type\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static analysis catches type mismatches\n",
    "Note that type checking does not work for the Sagemaker SDK by default, but I enabled it with the fix described [here](../../../design_decisions/typing_sagemaker_sdk.ipynb), which I have included in the setup defined in the [project's Makefile](../../../Makefile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>8: \u001b[1m\u001b[31merror:\u001b[m Return type \u001b[m\u001b[1m\"None\"\u001b[m of \u001b[m\u001b[1m\"create_step\"\u001b[m incompatible with return type \u001b[m\u001b[1m\"ProcessingStep\"\u001b[m in supertype \u001b[m\u001b[1m\"ProcessingStepFactoryInterface\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>8: \u001b[1m\u001b[31merror:\u001b[m Return type \u001b[m\u001b[1m\"None\"\u001b[m of \u001b[m\u001b[1m\"create_step\"\u001b[m incompatible with return type \u001b[m\u001b[1m\"ConfigurableRetryStep\"\u001b[m in supertype \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>14: \u001b[1m\u001b[31merror:\u001b[m Return type \u001b[m\u001b[1m\"int\"\u001b[m of \u001b[m\u001b[1m\"processor\"\u001b[m incompatible with return type \u001b[m\u001b[1m\"Processor\"\u001b[m in supertype \u001b[m\u001b[1m\"ProcessingStepFactoryInterface\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>18: \u001b[1m\u001b[31merror:\u001b[m Argument 1 of \u001b[m\u001b[1m\"get_processor_run_args\"\u001b[m is incompatible with supertype \u001b[m\u001b[1m\"ProcessingStepFactoryInterface\"\u001b[m; supertype defines the argument type as \u001b[m\u001b[1m\"SharedConfig\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>18: \u001b[34mnote:\u001b[m This violates the Liskov substitution principle\u001b[m\n",
      "<cell>18: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/common_issues.html#incompatible-overrides\u001b[m\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully ran cell\n"
     ]
    }
   ],
   "source": [
    "# Use\n",
    "# ====\n",
    "class FrameworkProcessingStepFactoryInterface(ProcessingStepFactoryInterface):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # This is not ok - return type is not of (sub)type `ProcessingStep``. Mypy catches this by default.\n",
    "    def create_step(self, shared_config) -> None:\n",
    "        return None\n",
    "\n",
    "    # This is not okay - return type is not of (sub)type `Processor`.\n",
    "    # However, mypy doesn't catch it by default - but it does here since I manually enabled type\n",
    "    # checking for Sagemaker-sdk.\n",
    "    def processor(self) -> int:\n",
    "        return 0\n",
    "\n",
    "    # This is not ok - argument type is not of (super)type `SharedConfig``. Mypy catches this by default.\n",
    "    def get_processor_run_args(self, shared_config: int) -> dict:\n",
    "        return {}\n",
    "\n",
    "    # This is ok\n",
    "    def get_processor_extra_kwargs(self, shared_config: SharedConfig) -> dict:\n",
    "        return {}\n",
    "\n",
    "\n",
    "framework_processing_step_interface = FrameworkProcessingStepFactoryInterface()\n",
    "framework_processing_step_interface.processor()\n",
    "print('\\nSuccessfully ran cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mypy does accept type generalizations following the Liskov Substitution Principle\n",
    "We are able to use more general or specific types in our implementation if they follow the Liskov Substitution Principle: Methods can return a more specific type, and method arguments can accept more general types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/thomas-22/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/thomas-22/.config/sagemaker/config.yaml\n",
      "Successfully ran cell\n"
     ]
    }
   ],
   "source": [
    "# Use\n",
    "# ====\n",
    "class FrameworkProcessingStepFactoryInterface(ProcessingStepFactoryInterface):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_step(self, shared_config: SharedConfig) -> ProcessingStep:\n",
    "        return ProcessingStep(name='preprocessing')\n",
    "\n",
    "    # This is okay: *Return* more *specific* type.\n",
    "    def processor(self) -> FrameworkProcessor:\n",
    "        return FrameworkProcessor(\n",
    "            estimator_cls=SKLearn,\n",
    "            framework_version='0.23-1',\n",
    "            role=get_execution_role(),\n",
    "            instance_type='ml.m5.xlarge',\n",
    "        )\n",
    "\n",
    "    # This is ok: *Accept* more *general* argument type.\n",
    "    def get_processor_run_args(self, shared_config: SharedConfig | dict) -> dict:\n",
    "        return {}\n",
    "\n",
    "    def get_processor_extra_kwargs(self, shared_config: SharedConfig) -> dict:\n",
    "        return {}\n",
    "\n",
    "\n",
    "framework_processing_step_interface = FrameworkProcessingStepFactoryInterface()\n",
    "framework_processing_step_interface.processor()\n",
    "print('Successfully ran cell')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
