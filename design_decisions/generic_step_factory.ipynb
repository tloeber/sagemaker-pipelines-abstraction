{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 1.0.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem with TypeAliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>32: \u001b[1m\u001b[31merror:\u001b[m Invalid index type \u001b[m\u001b[1m\"ProcessingStep | TrainingStep | CreateModelStep | TransformStep | TuningStep\"\u001b[m for \u001b[m\u001b[1m\"dict[type[ProcessingStep], str]\"\u001b[m; expected type \u001b[m\u001b[1m\"type[ProcessingStep]\"\u001b[m  \u001b[m\u001b[33m[index]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"ProcessingStep\"\u001b[m not callable  \u001b[m\u001b[33m[operator]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"TrainingStep\"\u001b[m not callable  \u001b[m\u001b[33m[operator]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"CreateModelStep\"\u001b[m not callable  \u001b[m\u001b[33m[operator]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"TransformStep\"\u001b[m not callable  \u001b[m\u001b[33m[operator]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"TuningStep\"\u001b[m not callable  \u001b[m\u001b[33m[operator]\u001b[m\n",
      "<cell>55: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>60: \u001b[1m\u001b[31merror:\u001b[m Cannot instantiate abstract class \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m with abstract attributes \u001b[m\u001b[1m\"_construct_run_args\"\u001b[m, \u001b[m\u001b[1m\"_instantiate_step_actor\"\u001b[m and \u001b[m\u001b[1m\"step_cls\"\u001b[m  \u001b[m\u001b[33m[abstract]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from typing import Generic, TypeVar, TypeAlias, Any, final\n",
    "from abc import abstractmethod\n",
    "\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.estimator import EstimatorBase\n",
    "\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep, \\\n",
    "    TuningStep, ConfigurableRetryStep\n",
    "\n",
    "# todo: decide how stringent this should be while still allowing user to add new step types\n",
    "StepType = TypeVar(\"StepType\", bound=ConfigurableRetryStep)\n",
    "StepActor: TypeAlias = Processor |  EstimatorBase  # todo: add more types as needed\n",
    "ConcreteStep: TypeAlias = ProcessingStep | TrainingStep | CreateModelStep | TransformStep | TuningStep\n",
    "\n",
    "\n",
    "class StepFactoryInterface(Generic[StepType]):\n",
    "    # @abstractmethod\n",
    "    # def __init__(self, step: StepType):\n",
    "    #     self.step_cls = StepType\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    # Note: This needs to return a *concrete* subclass of ConfigurableRetryStep\n",
    "    def step_cls(self) -> ConcreteStep:\n",
    "        ...\n",
    "\n",
    "    def step_type(self) -> str:\n",
    "        map = {\n",
    "            ProcessingStep: 'processor',\n",
    "        }\n",
    "\n",
    "        return map[self.step_cls]\n",
    "\n",
    "    @abstractmethod\n",
    "    def _instantiate_step_actor(self) -> StepActor:\n",
    "        \"\"\"Note: It is consistent with LSP for implementation to return a more *specific* type.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def _construct_run_args(self) -> dict[str, Any]:  # todo: create dataclass for return types\n",
    "        \"\"\"Note: It is consistent with LSP for implementation to return a more *specific* type.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def type(self):\n",
    "        return StepType\n",
    "\n",
    "    @final\n",
    "    def create_step(self) -> StepType:\n",
    "        step_actor: StepActor = self._instantiate_step_actor()\n",
    "        run_args: dict[str, Any] = self._construct_run_args()\n",
    "        # Type checker complains because you can't instantiate a ConfigurableRetryStep directly\n",
    "        # (it's abstract). Ignore for now, as I don't think it's easily possible to specify we're\n",
    "        # passing a concrete subclass.\n",
    "        return self.step_cls(\n",
    "            **{step: step_actor},\n",
    "            **run_args\n",
    "        )\n",
    "\n",
    "ProcessingStepFactoryInterface = StepFactoryInterface[ProcessingStep]\n",
    "psf = ProcessingStepFactoryInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying virtual subclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>41: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"StepType\"\u001b[m is a type variable and only valid in type context  \u001b[m\u001b[33m[misc]\u001b[m\n",
      "<cell>45: \u001b[1m\u001b[31merror:\u001b[m Type argument \u001b[m\u001b[1m\"ProcessingStep\"\u001b[m of \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m must be a subtype of \u001b[m\u001b[1m\"ConcreteStep\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n",
      "<cell>45: \u001b[1m\u001b[31merror:\u001b[m Value of type variable \u001b[m\u001b[1m\"StepType\"\u001b[m of \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m cannot be \u001b[m\u001b[1m\"ProcessingStep\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n",
      "<cell>46: \u001b[1m\u001b[31merror:\u001b[m Value of type variable \u001b[m\u001b[1m\"StepType\"\u001b[m of \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m cannot be \u001b[m\u001b[1m\"ProcessingStep\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n",
      "<cell>46: \u001b[1m\u001b[31merror:\u001b[m Cannot instantiate abstract class \u001b[m\u001b[1m\"BaseStepFactoryInterface\"\u001b[m with abstract attributes \u001b[m\u001b[1m\"_instantiate_step_actor\"\u001b[m and \u001b[m\u001b[1m\"construct_run_args\"\u001b[m  \u001b[m\u001b[33m[abstract]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from typing import Generic, TypeVar, TypeAlias, Any, final\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.estimator import EstimatorBase\n",
    "\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep, \\\n",
    "    TuningStep, ConfigurableRetryStep\n",
    "\n",
    "StepActor: TypeAlias = Processor |  EstimatorBase  # todo: add more types as needed\n",
    "class ConcreteStep(ABC):\n",
    "    ...\n",
    "\n",
    "ConcreteStep.register(ProcessingStep)\n",
    "ConcreteStep.register(TrainingStep)\n",
    "ConcreteStep.register(CreateModelStep)\n",
    "ConcreteStep.register(TransformStep)\n",
    "ConcreteStep.register(TuningStep)\n",
    "\n",
    "# todo: decide how stringent this should be while still allowing user to add new step types\n",
    "StepType = TypeVar(\"StepType\", bound=ConcreteStep)\n",
    "class StepFactoryInterface(Generic[StepType]):\n",
    "    @abstractmethod\n",
    "    def _instantiate_step_actor(self) -> StepActor:\n",
    "        \"\"\"Note: It is consistent with LSP for implementation to return a more *specific* type.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def construct_run_args(self) -> dict[str, Any]:  # todo: create dataclass for return types\n",
    "        \"\"\"Note: It is consistent with LSP for implementation to return a more *specific* type.\"\"\"\n",
    "        # Changed: needs to include stepactor, e.g. processor=processor\n",
    "        ...\n",
    "\n",
    "    @final\n",
    "    def create_step(self) -> StepType:\n",
    "        step_actor: StepActor = self._instantiate_step_actor()\n",
    "        run_args: dict[str, Any] = self.construct_run_args()\n",
    "        # Type checker complains because you can't instantiate a ConfigurableRetryStep directly\n",
    "        # (it's abstract). Ignore for now, as I don't think it's easily possible to specify we're\n",
    "        # passing a concrete subclass.\n",
    "        return StepType(\n",
    "            **run_args\n",
    "        )\n",
    "\n",
    "ProcessingStepFactoryInterface = StepFactoryInterface[ProcessingStep]\n",
    "# psf = ProcessingStepFactoryInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only create basic interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, TypeVar, TypeAlias, Any, final\n",
    "from abc import abstractmethod\n",
    "\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.estimator import EstimatorBase\n",
    "\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep, \\\n",
    "    TuningStep, ConfigurableRetryStep\n",
    "\n",
    "# todo: decide how stringent this should be while still allowing user to add new step types\n",
    "StepType = TypeVar(\"StepType\", bound=ConfigurableRetryStep)\n",
    "\n",
    "\n",
    "class StepFactoryInterface(Generic[StepType]):\n",
    "    @abstractmethod\n",
    "    def create_step(self) -> StepType:\n",
    "        ...\n",
    "\n",
    "ProcessingStepFactoryInterface = StepFactoryInterface[ProcessingStep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: by contrast to earlier designs, create_step does not require a step_config to be passed here as an argument. This simplify the interface considerably because we don't have to worry about getting the right type of step_config for a given step_type. The problem is that while we can simply *return more specific* step types in subclasses (such as a ProcessingStep instead of a ConfigurableRetryStep), we can**not** require a *more specific argument* for subclasses (for example requiring a ProcessingStepConfig for a ProcessingStepFactory), as this would violate the Liskov Substitution Principal.\n",
    "\n",
    "This problem would not even be easily solved by using generics, because it is not obvious how we can go from my given Steptype to the associated StepConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "\n",
    "# IMPLEMENTATION\n",
    "# ===============\n",
    "\n",
    "class FrameworkProcessingStepFactory(ProcessingStepFactoryInterface):\n",
    "    def __init__(\n",
    "        self,\n",
    "        step_name: str,\n",
    "        config_facade_cls: type[FrameworkProcessingConfigFacade], # todo: generalize type\n",
    "    ):\n",
    "        self._step_name = step_name\n",
    "        self._config_facade_cls = config_facade_cls\n",
    "\n",
    "    def create_step(self) -> ProcessingStep:\n",
    "        return ProcessingStep(\n",
    "            **args,\n",
    "            depends_on=self.config_facade._steptype_specific_config.depends_on,\n",
    "        )\n",
    "\n",
    "    def instantiate_config_facade(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        steptype_specific_config: ProcessingConfig,\n",
    "        additional_config: FrameworkProcessingConfig,\n",
    "    ):\n",
    "        # problem: type checker doesn't know when this attributes exists\n",
    "        self.config_facade = self._config_facade_cls(\n",
    "            shared_config=shared_config,\n",
    "            steptype_specific_config=steptype_specific_config,\n",
    "            additional_config=additional_config,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def step_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Facade calls this method before create_step(), so it can retrieve the right config first.\n",
    "        \"\"\"\n",
    "        return self._step_name\n",
    "\n",
    "    # todo: Generalize types to other processors\n",
    "    def _processor(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "        sagemaker_session: PipelineSession | Session | LocalPipelineSession,\n",
    "        role_arn: str,\n",
    "    ) -> Processor:  # type: ignore\n",
    "        \"\"\"Instantiate processor.\"\"\"\n",
    "\n",
    "        # Get processor class from classname string in config file\n",
    "\n",
    "        return processor_cls(\n",
    "\n",
    "        )  # type: ignore\n",
    "\n",
    "    def _get_processor_run_args(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "    ) -> FrameworkProcessorRunArgs:\n",
    "\n",
    "        def _construct_outputs(\n",
    "            step_config_facade: FrameworkProcessingConfigFacade,\n",
    "        ) -> list[ProcessingOutput]:\n",
    "            \"\"\"Constructs list of ProcessingOutput from configs.\"\"\"\n",
    "            outputs: list[ProcessingOutput] = []\n",
    "            for output_config in step_config_facade.steptype_specific_config.outputs:\n",
    "                output = ProcessingOutput(\n",
    "                    source=f\"/opt/ml/{self.step_type}/{step_config_facade.step_name}/{output_config.output_name}\",\n",
    "                    destination=f\"{step_config_facade.s3_output_folder}/{output_config.output_name}\",\n",
    "                    **output_config,\n",
    "                )\n",
    "                outputs.append(output)\n",
    "            return outputs\n",
    "\n",
    "        skl_run_args = FrameworkProcessorRunArgs(\n",
    "            inputs = [\n",
    "                ProcessingInput(\n",
    "                    source=step_config_facade.input_s3_dir,\n",
    "                    destination=f'/opt/ml/{self.step_type}/{step_config_facade.step_name}/input/'\n",
    "                ),\n",
    "            ],\n",
    "            outputs = _construct_outputs(step_config_facade),\n",
    "            source_dir=f\"code/{_step_config_facade.step_name}/\",\n",
    "            code=f'{step_config_facade.step_name}.py', # Hard-code to avoid extra config value\n",
    "            arguments=None, # Todo: Decide whether this should come from configuration. May depend on type of step.\n",
    "        )\n",
    "        return skl_run_args\n",
    "\n",
    "fw_proc_step_factory = FrameworkProcessingStepFactory(step_name='preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple factory\n",
    "This makes better use of factory, because depending on arg passed to it, it creates a different type of step. Otherwise, we may as well us strategy pattern (only use of factory is to construct step later when configs etc are known - but a given factory always produces same kind of step, except from configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1812735520.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    return factory.create_step(step_config: dict[str: Any])\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from typing import ClassVar\n",
    "\n",
    "\n",
    "class StepFactoryInterface(ABC):\n",
    "    @abstractmethod\n",
    "    def create_step(self, step_name: str) -> ConfigurableRetryStep:\n",
    "        ...\n",
    "\n",
    "\n",
    "class StepFactoryWrapper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        stepfactory_lookup_table: dict[str, StepFactoryInterface],\n",
    "    ):\n",
    "        self._stepfactory_lookup_table = stepfactory_lookup_table\n",
    "\n",
    "    # def set_stepname_to_factory_map(\n",
    "    #     self,\n",
    "    #     stepname_to_factory_map: dict[str, StepFactoryInterface],\n",
    "    # ):\n",
    "    #     self._steptype_to_factory_map = stepname_to_factory_map\n",
    "\n",
    "    # def update_stepname_to_factory_map(\n",
    "    #     self,\n",
    "    #     additional_stepname_to_factory_map: dict[str, StepFactoryInterface],\n",
    "    # ):\n",
    "    #     self._steptype_to_factory_map.update(\n",
    "    #         additional_stepname_to_factory_map,\n",
    "    #     )\n",
    "\n",
    "    def create_step(self, step_name: str) -> ConfigurableRetryStep:\n",
    "        # step name identifies config location.\n",
    "        step_config: dict[str, Any] = load_step_config_dict_from_yaml(step_name=step_name)\n",
    "        # Before validating config, we need to know for what type of step it is.\n",
    "        # todo: Make knowable for typechecker that this key exists. Use typeddict (with optional keys)?\n",
    "        step_type = step_config['step_type']\n",
    "        # Look up which factory to use, based on step_type speified in config\n",
    "        factory: StepFactoryInterface = self._stepfactory_lookup_table[step_type]\n",
    "        return factory.create_step(step_config=step_config)\n",
    "\n",
    "\n",
    "class _FrameworkProcessingStepFactory():\n",
    "    def create_step(self, step_config: dict[str: Any]) -> ProcessingStep:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the StepFactoryWrapper is decoupled from the specific StepFactory that will be used to create the step. The latter is determined by a lookup table, which is injected into to the StepFactoryWrapper during initialization.\n",
    "\n",
    "The downside is that this is less convenient for simple use cases, where the user is content with choosing only from the default factories that ship with the library. To remediate this disadvantage, we can simply create a facade, which instantiates the StepFactoryWrapper with the default lookup table. More advanced users, by contrast, can directly import this default lookup table and customize it to point to custom StepFactory implementations. In a second step, they then initialize the StepFactoryWrapper directly, passing it the custom lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher-level-interface\n",
    "# ======================\n",
    "\n",
    "stepfactory_lookup_table: dict[str, StepFactoryInterface] = {\n",
    "    'FrameworkProcessor': _FrameworkProcessingStepFactory,\n",
    "}\n",
    "\n",
    "# This is what user will import\n",
    "stepfactory_wrapper = StepFactoryWrapper(\n",
    "    stepfactory_lookup_table=stepfactory_lookup_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower-level interface (if customization of factories is needed)\n",
    "# ===============================================================\n",
    "\n",
    "# Implement custom stepfactory\n",
    "class  _CustomProcessingStepFactory():\n",
    "    ...\n",
    "\n",
    "# add it to the lookup table\n",
    "stepfactory_lookup_table.update(\n",
    "    {\n",
    "        'CustomProcessor': _CustomProcessingStepFactory,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Instantiate StepFactory with customized lookup table\n",
    "customized_step_factory = StepFactoryWrapper(\n",
    "    stepfactory_lookup_table=stepfactory_lookup_table\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
