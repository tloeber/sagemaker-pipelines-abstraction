{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facade + Factory-Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_mypy extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_mypy\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imports and folder paths work\n",
    "# todo: Instead create python package and install locally\n",
    "import os, sys\n",
    "os.chdir(\n",
    "    f'{os.environ[\"HOME\"]}/repos/sagemaker-pipelines-abstraction/src'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from functools import cached_property\n",
    "from typing import Literal, Callable, TypeAlias, Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import TypeVar, Generic\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_settings import BaseSettings\n",
    "from loguru import logger\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import Step\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.workflow.steps import ConfigurableRetryStep, ProcessingStep\n",
    "from sm_pipelines_oo.shared_config_schema import Environment\n",
    "\n",
    "from sm_pipelines_oo.shared_config_schema import SharedConfig, Environment\n",
    "# from sm_pipelines_oo.steps.interfaces import StepFactoryInterface\n",
    "from sm_pipelines_oo.aws_connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.utils import load_pydantic_config_from_file\n",
    "from sm_pipelines_oo.aws_connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.aws_connector.implementation import AWSConnector, LocalAWSConnector, \\\n",
    "    create_aws_connector\n",
    "from sm_pipelines_oo.pipeline_wrapper import PipelineWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "# ==========\n",
    "class StepConfig(BaseSettings):\n",
    "    \"\"\"This class defines required fields for all Step-specific configs.\"\"\"\n",
    "    # todo: decide how to load this from file. E.g., json-encoded list of step names, e.g.: [\"step1\", \"step2\"]\n",
    "    depends_on: list[str] | None = None\n",
    "\n",
    "from typing import TypedDict\n",
    "class _OutputConfigs(TypedDict):\n",
    "    output_name: str\n",
    "    output_filename: str\n",
    "\n",
    "class ProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    This class defines all the config values shared by any subtype of processing step.\n",
    "    \"\"\"\n",
    "    input_filename: str\n",
    "    outputs: list[_OutputConfigs]\n",
    "    instance_type: str\n",
    "    instance_count: int\n",
    "    sklearn_framework_version: str\n",
    "    code_filename: str\n",
    "\n",
    "class FrameworkProcessingConfig(ProcessingConfig):\n",
    "    \"\"\"\n",
    "    This class defines all the config values that are specific to a FrameworkProcessor.\n",
    "    It inherits all fiels shared by all steps from the ProcessingConfig class.\n",
    "    \"\"\"\n",
    "    # While it would be nice if we could set `estimator_cls=SKLearn`in the config file, we would\n",
    "    # have to use `eval()` to construct a python object from the string, which is a potential\n",
    "    # security vulnerability.)\n",
    "    estimator_cls: Literal['SKLearn'] = 'SKLearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic StepConfig FACADE\n",
    "# =========================\n",
    "\n",
    "# Each of the types must be a subclass of BaseSettings\n",
    "StepSpecificConfigType = TypeVar(\"StepSpecificConfigType\", bound=BaseSettings) # todo: can we narrow the type binding?\n",
    "AdditionalConfigType = TypeVar(\"AdditionalConfigType\", bound=BaseSettings)\n",
    "\n",
    "@dataclass\n",
    "class StepConfigFacade(\n",
    "    Generic[StepSpecificConfigType, AdditionalConfigType]\n",
    "):\n",
    "    step_name: str\n",
    "    step_config: StepConfig\n",
    "    steptype_specific_config: StepSpecificConfigType\n",
    "    additional_config: AdditionalConfigType\n",
    "\n",
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    FrameworkProcessingConfig,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step*Config* FACADE V2\n",
    "# =====================\n",
    "\n",
    "class StepConfigFacadeInterface(ABC):\n",
    "    # @abstractmethod\n",
    "    # def __init__(\n",
    "    #     self,\n",
    "    #     shared_config: SharedConfig,\n",
    "    #     steptype_specific_config: StepSpecificConfig,\n",
    "    #     additional_config: AdditionalConfig,\n",
    "    # ) -> None:\n",
    "        # ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def shared_config(self) -> SharedConfig:\n",
    "        ...\n",
    "\n",
    "    # @property\n",
    "    # @abstractmethod\n",
    "    # def step_config(self) -> StepSpecificConfig:\n",
    "    #     ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_name(self) -> str:\n",
    "        \"\"\"StepConfigFacade needs to know step name in order to load step-configs from file.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def construct_instantiation_args(self) -> dict[str, Any]: # todo: use more concrete types\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def construct_run_args(self) -> dict[str, Any]:  # todo: use more concrete types\n",
    "        ...\n",
    "\n",
    "\n",
    "class ProcessingConfigFacadeInterface(StepConfigFacadeInterface):\n",
    "    # @abstractmethod\n",
    "    # def __init__(\n",
    "    #     self,\n",
    "    #     shared_config: SharedConfig,\n",
    "    #     steptype_specific_config: ProcessingConfig, # todo: this violates LSP! does it make sense to use generics here?\n",
    "    #     additional_config: AdditionalConfig,\n",
    "    # ) -> None:\n",
    "        # ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def shared_config(self) -> SharedConfig:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_name(self) -> str:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def construct_instantiation_args(self) -> dict[str, Any]: # todo: use more concrete types\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def construct_run_args(self) -> dict[str, Any]:  # todo: use more concrete types\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1352950874.py, line 113)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 113\u001b[0;36m\u001b[0m\n\u001b[0;31m    fw_proc_config_facade =\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Classes defining args\n",
    "# =====================\n",
    "\n",
    "class FrameworkProcessorInstantiationArgs(TypedDict):\n",
    "    framework_version: str\n",
    "    instance_type: str\n",
    "    instance_count: int\n",
    "    base_job_name: str\n",
    "    sagemaker_session: Any\n",
    "    role: str\n",
    "\n",
    "class ProcessorRunArgs(TypedDict):\n",
    "    name: str\n",
    "    inputs: list[ProcessingInput]\n",
    "    outputs: list[ProcessingOutput]\n",
    "    arguments: list[str] | None\n",
    "\n",
    "\n",
    "class FrameworkProcessorRunArgs(TypedDict):\n",
    "    name: str\n",
    "    inputs: list[ProcessingInput]\n",
    "    outputs: list[ProcessingOutput]\n",
    "    arguments: list[str] | None\n",
    "    source_dir: str\n",
    "    code: str\n",
    "\n",
    "\n",
    "class FrameworkProcessingConfigFacade(StepConfigFacadeInterface):\n",
    "    def __init__(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        steptype_specific_config: ProcessingConfig,\n",
    "        additional_config: FrameworkProcessingConfig,\n",
    "    ) -> None:\n",
    "        self._shared_config = shared_config\n",
    "        self._steptype_specific_config = steptype_specific_config\n",
    "        self._additional_config = additional_config\n",
    "\n",
    "        # This determines how to construct the estimator object from the string in the config file, avoiding the\n",
    "        # use of `eval`, which is a potential security vulnerability.\n",
    "        self._str_to_cls_mapping: dict[str, Any] = {  # todo:  find supertype\n",
    "            'SKLearn': SKLearn,\n",
    "        }\n",
    "\n",
    "    def support_additional_estimators(self, additional_estimator_mapping: dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Allow user to add additional estimators (following the open-closed principle).\n",
    "\n",
    "        Note: We don't use composition, because passing this mapping to constructor would violate\n",
    "        the shared interface for StepFactory's constructor. Instead, we add an addiitonal method\n",
    "        to allow updating the mapping.\n",
    "        \"\"\"\n",
    "        self._str_to_cls_mapping.update(additional_estimator_mapping)\n",
    "\n",
    "    @property\n",
    "    def processor_cls(self) -> Any:  # todo: find supertype\n",
    "        _processor_cls_name: str = self._additional_config.estimator_cls\n",
    "        # Look up class name in mapping, and return corresponding class\n",
    "        return self._str_to_cls_mapping[_processor_cls_name]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def shared_config(self) -> SharedConfig:\n",
    "        return self._shared_config\n",
    "\n",
    "    # @property\n",
    "    # @abstractmethod\n",
    "    # def step_name(self) -> str:\n",
    "\n",
    "\n",
    "    def construct_instantiation_args(self) -> FrameworkProcessorInstantiationArgs: # todo: use more concrete types\n",
    "        return FrameworkProcessorInstantiationArgs(\n",
    "            framework_version=self._steptype_specific_config.sklearn_framework_version,\n",
    "            instance_type=self._steptype_specific_config.instance_type,\n",
    "            instance_count=self._steptype_specific_config.instance_count,\n",
    "            base_job_name=self.step_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            role=role_arn,\n",
    "            # **self._processor_extra_kwargs,\n",
    "\n",
    "        )\n",
    "\n",
    "    # def construct_run_args(self) -> FrameworkProcessorRunArgs:  # todo: use more concrete types\n",
    "    #     return FrameworkProcessorRunArgs(\n",
    "    #         name=step_config_facade.step_name,\n",
    "    #         processor=self._processor(\n",
    "    #             step_config_facade=step_config_facade,\n",
    "    #             sagemaker_session=aws_connector.sm_session,\n",
    "    #             role_arn=aws_connector.role_arn,\n",
    "    #         ),\n",
    "    #         inputs=[\n",
    "    #             ProcessingInput(\n",
    "    #                 source=step_config_facade.steptype_specific_configs.input_filename,\n",
    "    #                 destination=step_config_facade.steptype_specific_configs.output_data,\n",
    "    #                 s3_data_type='S3Prefix',\n",
    "    #                 s3_input_mode='File',\n",
    "    #             )\n",
    "    #         ],\n",
    "    #         outputs=[\n",
    "    #             ProcessingOutput(\n",
    "    #                 source=step_config_facade.steptype_specific_configs.output_data,\n",
    "    #                 destination=step_config_facade.steptype_specific_configs.output_data,\n",
    "    #                 s3_upload_mode='EndOfJob',\n",
    "    #             )\n",
    "    #         ],\n",
    "    #         code=step_config_facade.steptype_specific_configs.code_filename,\n",
    "    #     )\n",
    "\n",
    "\n",
    "fw_proc_config_facade ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config FACTORY\n",
    "# ===============\n",
    "class ConfigFactoryInterface:\n",
    "    \"\"\"Abstraction layer that allows accessing both shared config and step configs.\"\"\"\n",
    "    @abstractmethod\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> StepConfigFacade:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example configs\n",
    "fw_proc_configs = FrameworkProcessingConfigFacade(\n",
    "    step_name='pre_processing',\n",
    "    steptype_specific_configs=ProcessingConfig(\n",
    "        input_filename='input.parquet',\n",
    "        output_train_filename='output_train.parquet',\n",
    "        output_val_filename='output_val.parquet',\n",
    "        output_test_filename='output_test.parquet',\n",
    "        instance_type='local',\n",
    "        instance_count=1,\n",
    "        sklearn_framework_version='0.23-1',\n",
    "        code_filename='pre_processing.py',\n",
    "    ),\n",
    "    additional_configs=FrameworkProcessingConfig(\n",
    "        estimator_cls='SKLearn',\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "class MockFWPConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    This class is used to create a mock config for testing purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> FrameworkProcessingConfigFacade:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        if step_name == 'processing':\n",
    "            return fw_proc_configs\n",
    "        else:\n",
    "            raise NotImplementedError(f'No config defined for step {step_name}')\n",
    "\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        return SharedConfig(\n",
    "            project_name=\"test\",\n",
    "            project_version='v0.0',\n",
    "            region='us-east-1',\n",
    "            role_name='test_role',\n",
    "            project_bucket_name='test-bucket',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    The pipeline faÃ§ade will usually use this class to load configs. Only explicitly specify a\n",
    "    different class implementing the same interface for testing purposes (e.g., to directly define\n",
    "    config rather than reading from file).\n",
    "    \"\"\"\n",
    "    # todo: Put reading of configs from file, etc, here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StepType: TypeAlias = Literal['processing', 'training', 'model', 'evaluation']\n",
    "\n",
    "class PathFactory:\n",
    "    # todo: use general step config, once stable.\n",
    "    # todo: Add interface (or rename to distinguish from actual factory patterns)\n",
    "    def __init__(self, step_config_facade: StepConfigFacade, shared_config: SharedConfig):\n",
    "        self._step_config_facade = step_config_facade\n",
    "        self._shared_config = shared_config\n",
    "\n",
    "    # S3 Folder Paths\n",
    "    # ===============\n",
    "\n",
    "    @cached_property\n",
    "    def _default_s3_data_folder(self) -> str:\n",
    "        default_bucket_name = self._shared_config.project_bucket_name\n",
    "        project_version = self._shared_config.project_version\n",
    "        step_name = self._step_config_facade.step_name\n",
    "        return f\"s3://{default_bucket_name}/{project_version}/{step_name}\"\n",
    "\n",
    "    @cached_property\n",
    "    def s3_input_folder(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns custom s3 folder with input data, if provided. Otherwise returns default s3 input\n",
    "        folder.\n",
    "        \"\"\"\n",
    "        custom_s3_folder: str | None = self._step_config_facade.input_s3_dir\n",
    "        default_s3_folder = f\"{self._default_s3_data_folder}/input\"\n",
    "        return  custom_s3_folder or default_s3_folder\n",
    "\n",
    "    @cached_property\n",
    "    def s3_output_folder(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns custom s3 folder with output data, if provided. Otherwise returns default s3 output\n",
    "        folder.\n",
    "        \"\"\"\n",
    "        custom_s3_folder: str | None = self._step_config_facade.output_s3_dir\n",
    "        default_s3_folder = f'{self._default_s3_data_folder}/output'\n",
    "        return  custom_s3_folder or default_s3_folder\n",
    "\n",
    "    # Local Folder Paths\n",
    "    # =================\n",
    "\n",
    "    def get_local_folderpath(self, step_type: StepType) -> str:\n",
    "        # Note that `/opt/ml/${STEP_TYPE}/` is *required* by Sagemaker.\n",
    "        # todo: Use more precise type annotation? (Create type for StepType)\n",
    "        step_name: str = self._step_config_facade.step_name\n",
    "        return f'/opt/ml/{step_type}/{step_name}'\n",
    "\n",
    "    @property\n",
    "    def source_dir(self) -> str:\n",
    "        # Hard-code source_directory name to simplify configs.\n",
    "        return f\"code/{self._step_config_facade.step_name}/\"\n",
    "\n",
    "    @property\n",
    "    def step_code_file(self) -> str:\n",
    "        # Hard-code name of step's code file to simplify configs.\n",
    "        return f\"{self._step_config_facade.step_name}.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Abstract* step factory\n",
    "# =======================\n",
    "\n",
    "class AbstractStepFactory(ABC):\n",
    "    \"\"\"This is an interface for concrete step factories.\"\"\"\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        step_config_facade: StepConfigFacade,\n",
    "        path_factory: PathFactory, # todo: create interface\n",
    "        aws_connector: AWSConnectorInterface,\n",
    "\n",
    "    ) -> ConfigurableRetryStep:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_name(self) -> str:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_type(self) -> StepType:\n",
    "        \"\"\"This tells us where Sagemaker stores local copy of data, e.g., /opt/ml/processing/.\"\"\"\n",
    "        ...\n",
    "\n",
    "# *Concrete* step factories\n",
    "# =========================\n",
    "\n",
    "class ProcessingStepFactoryInterface(AbstractStepFactory):\n",
    "    \"\"\"\n",
    "    This subclass is distinguished only by more specific return type for step (and step_type name).\n",
    "    .\"\"\"\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        step_config_facade: StepConfigFacade,\n",
    "        path_factory: PathFactory, # todo: create interface\n",
    "        aws_connector: AWSConnectorInterface,\n",
    "    ) -> ProcessingStep:\n",
    "         ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_type(self) -> Literal['processing']:\n",
    "        ...\n",
    "\n",
    "\n",
    "class FrameworkProcessorFactory(ProcessingStepFactoryInterface):\n",
    "    # todo: Check if there is an inbuilt type for fwp-step.\n",
    "    @property\n",
    "    def step_type(self) -> Literal['processing']:\n",
    "        return 'processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "\n",
    "# Step Factory IMPLEMENTATION\n",
    "# ===========================\n",
    "\n",
    "class FrameworkProcessingStepFactory(ProcessingStepFactoryInterface):\n",
    "    \"\"\"\n",
    "    shared config etc will be passed during create_step().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        step_name: str,\n",
    "        config_facade_cls: type[FrameworkProcessingConfigFacade], # todo: generalize type\n",
    "    ):\n",
    "        self._step_name = step_name\n",
    "        self._config_facade_cls = config_facade_cls\n",
    "\n",
    "    def instantiate_config_facade(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        steptype_specific_config: ProcessingConfig,\n",
    "        additional_config: FrameworkProcessingConfig,\n",
    "    ):\n",
    "        # problem: type checker doesn't know when this attributes exists\n",
    "        self.config_facade = self._config_facade_cls(\n",
    "            shared_config=shared_config,\n",
    "            steptype_specific_config=steptype_specific_config,\n",
    "            additional_config=additional_config,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def step_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Facade calls this method before create_step(), so it can retrieve the right config first.\n",
    "        \"\"\"\n",
    "        return self._step_name\n",
    "\n",
    "    # todo: Generalize types to other processors\n",
    "    def _processor(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "        sagemaker_session: PipelineSession | Session | LocalPipelineSession,\n",
    "        role_arn: str,\n",
    "    ) -> Processor:  # type: ignore\n",
    "        \"\"\"Instantiate processor.\"\"\"\n",
    "\n",
    "        # Get processor class from classname string in config file\n",
    "\n",
    "        return processor_cls(\n",
    "\n",
    "        )  # type: ignore\n",
    "\n",
    "    def _get_processor_run_args(\n",
    "        self,\n",
    "        step_config_facade: FrameworkProcessingConfigFacade,\n",
    "    ) -> FrameworkProcessorRunArgs:\n",
    "\n",
    "        def _construct_outputs(\n",
    "            step_config_facade: FrameworkProcessingConfigFacade,\n",
    "        ) -> list[ProcessingOutput]:\n",
    "            \"\"\"Constructs list of ProcessingOutput from configs.\"\"\"\n",
    "            outputs: list[ProcessingOutput] = []\n",
    "            for output_config in step_config_facade.steptype_specific_config.outputs:\n",
    "                output = ProcessingOutput(\n",
    "                    source=f\"/opt/ml/{self.step_type}/{step_config_facade.step_name}/{output_config.output_name}\",\n",
    "                    destination=f\"{step_config_facade.s3_output_folder}/{output_config.output_name}\",\n",
    "                    **output_config,\n",
    "                )\n",
    "                outputs.append(output)\n",
    "            return outputs\n",
    "\n",
    "        skl_run_args = FrameworkProcessorRunArgs(\n",
    "            inputs = [\n",
    "                ProcessingInput(\n",
    "                    source=step_config_facade.input_s3_dir,\n",
    "                    destination=f'/opt/ml/{self.step_type}/{step_config_facade.step_name}/input/'\n",
    "                ),\n",
    "            ],\n",
    "            outputs = _construct_outputs(step_config_facade),\n",
    "            source_dir=f\"code/{_step_config_facade.step_name}/\",\n",
    "            code=f'{step_config_facade.step_name}.py', # Hard-code to avoid extra config value\n",
    "            arguments=None, # Todo: Decide whether this should come from configuration. May depend on type of step.\n",
    "        )\n",
    "        return skl_run_args\n",
    "\n",
    "    # todo: Add more specific return type (may have to create custom type, but check Sagemaker sdk code again)\n",
    "    def create_step(\n",
    "            self,\n",
    "            shared_config: SharedConfig,\n",
    "            step_config_facade: StepConfigFacade,\n",
    "            path_factory: PathFactory,\n",
    "            aws_connector: AWSConnectorInterface,\n",
    "        ) -> ProcessingStep:\n",
    "        # todo: think about how to create these here\n",
    "        step_config_facade = fw_proc_configs\n",
    "\n",
    "        return ProcessingStep(\n",
    "            **args,\n",
    "            depends_on=self.config_facade._steptype_specific_config.depends_on,\n",
    "        )\n",
    "fw_proc_step_factory = FrameworkProcessingStepFactory(step_name='preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from step_utils import FrameworkProcessingConfigFacade, ProcessingOutput\n",
    "\n",
    "def test_construct_outputs(setup):\n",
    "    data_locations, step_config, shared_config = setup\n",
    "\n",
    "    # Create a FrameworkProcessingConfigFacade instance\n",
    "    step_config_facade = FrameworkProcessingConfigFacade()\n",
    "    step_config_facade.step_name = 'step1'\n",
    "    step_config_facade.s3_output_folder = 's3://test_bucket/v1/step1/output'\n",
    "\n",
    "    # Create a ProcessingOutput instance and add it to the outputs of the step_config_facade\n",
    "    output_config = ProcessingOutput(output_name='output1')\n",
    "    step_config_facade.steptype_specific_config.outputs = [output_config]\n",
    "\n",
    "    outputs = data_locations._construct_outputs(step_config_facade)\n",
    "\n",
    "    assert len(outputs) == 1\n",
    "    assert isinstance(outputs[0], ProcessingOutput)\n",
    "    assert outputs[0].source == '/opt/ml/type1/step1/output1'\n",
    "    assert outputs[0].destination == 's3://test_bucket/v1/step1/output/output1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline facade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineFacade:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each step factory is instantiated with its step_name, thus identifying step_config\n",
    "        step_factories: list[AbstractStepFactory],\n",
    "        env: Environment,\n",
    "        config_factory: ConfigFactoryInterface | None,\n",
    "        path_factory: PathFactory,\n",
    "        estimator_name_to_class_mapping: dict[str, Any] | None = None,\n",
    "    ) -> None:\n",
    "        self._env: Environment = env\n",
    "        self._step_factories = step_factories\n",
    "        self._config_factory = config_factory\n",
    "        self._estimator_name_to_class_mapping = estimator_name_to_class_mapping\n",
    "        self._path_factory = path_factory\n",
    "\n",
    "        # Derived attributes\n",
    "        # ==================\n",
    "        # Note that we are using the config_factory *property*, which is always defined\n",
    "        self._shared_config: SharedConfig = self.config_factory.get_shared_config(env=self._env)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def estimator_name_to_class_mapping(self) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        This determines how to construct the estimator object from the string in the config file, avoiding the\n",
    "        use of `eval`, which is a potential security vulnerability.\n",
    "        \"\"\"\n",
    "        # Default mapping\n",
    "        if self._estimator_name_to_class_mapping is None:\n",
    "            return {'SKLearn': SKLearn} # todo: add more estimators\n",
    "\n",
    "        # Allow user to override default to specify additional estimator classes\n",
    "        else:\n",
    "            return self._estimator_name_to_class_mapping\n",
    "\n",
    "    @property\n",
    "    def config_factory(self) -> ConfigFactoryInterface:\n",
    "        # Generally, default is fine\n",
    "        if self._config_factory is None:\n",
    "            return DefaultConfigFactory()\n",
    "\n",
    "        # Allow user to pass a custom factory, e.g. a mock factory for testing.\n",
    "        else:\n",
    "            return self._config_factory\n",
    "\n",
    "    @cached_property\n",
    "    def _steps(self) -> list[Step]:\n",
    "        steps: list[Step] = []\n",
    "        for step_factory in self._step_factories:\n",
    "            step_configs: StepConfigFacade = self.config_factory.get_step_configs(\n",
    "                env=self._env,\n",
    "                step_name=step_factory.step_name,\n",
    "            )\n",
    "            step: Step = step_factory.create_step(\n",
    "                shared_config=self._shared_config,\n",
    "                step_configs=step_configs,\n",
    "                path_factory=self._path_factory,\n",
    "            )\n",
    "            steps.append(step)\n",
    "        return steps\n",
    "\n",
    "    @cached_property\n",
    "    def _aws_connector(self) -> AWSConnectorInterface:\n",
    "        \"\"\"\n",
    "        This code makes connector.implementation.create_aws_connector() redundant, except for use\n",
    "        outside of pipeline.\n",
    "        Todo: decide where to put code for the latter case.\n",
    "        \"\"\"\n",
    "        # todo: make this a factory, so we can move this logic out of facade?\n",
    "        if self._env == 'local':\n",
    "            return LocalAWSConnector()\n",
    "        else:\n",
    "            return AWSConnector(\n",
    "                environment=self._env,\n",
    "                # this error will resolve once we don't use SharedConfig from this notebook but\n",
    "                # library's AWSConnector.\n",
    "                shared_config=self._shared_config,  # type: ignore\n",
    "                run_as_pipeline=True\n",
    "            )\n",
    "\n",
    "    @cached_property\n",
    "    def _pipeline(self) -> Pipeline:\n",
    "        \"\"\"\n",
    "        We could make this a private  method and call it in __init__(), but this is shorter.\n",
    "        \"\"\"\n",
    "        pipeline_name = f'{self._shared_config.project_name}-{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "        pipeline = Pipeline(\n",
    "            name=pipeline_name,\n",
    "            steps=self._steps,\n",
    "            sagemaker_session=self._aws_connector.sm_session,\n",
    "        )\n",
    "        pipeline.create(role_arn=self._aws_connector.role_arn)\n",
    "        return pipeline\n",
    "\n",
    "    def run(self) -> None:\n",
    "        try:\n",
    "            logger.info(f\"Starting pipeline run for project {self._shared_config.project_name}\")\n",
    "            execution = self._pipeline.start()\n",
    "            execution.wait()\n",
    "            execution.list_steps()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= PipelineFacade(\n",
    "    step_factories=[fw_proc_step_factory],\n",
    "    env='local',\n",
    "    config_factory=MockFWPConfigFactory(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
