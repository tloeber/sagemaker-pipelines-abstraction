{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 1.0.5\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imports and folder paths work\n",
    "# todo: Instead create python package and install locally\n",
    "import os, sys\n",
    "os.chdir(\n",
    "    f'{os.environ[\"HOME\"]}/repos/sagemaker-pipelines-abstraction/src'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "from pydantic_settings import BaseSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision 1: Composition versus Inheritance\n",
    "- Composition: separate config objects for shared, Specific, and any additional config values\n",
    "- inheritance: single config, inheriting from a comment step config)\n",
    "- Decision: Use composition\n",
    "  - Generally, it is a OOP best practice to use composition over inheritance, because inheritance leads to tight coupling. \n",
    "  - However, the downside of composition in our case is that it requires use of more advanced programming patterns that not all python programmers may be familiar off, namely the use of Generics (at least if you want to have type safety, which should be in negotiable). \n",
    "  - Furthermore, a small additional downside of composition is that it makes the configs a little more awkward, because the config object is now of wrapper composed of multiple different config's. \n",
    "  - Nevertheless, I think these downsides are easily worth it for the better maintainability of composition. This decision has been reinforced by working with the different type of Sagemaker steps, which I think are much more frustrating to work with than they should be as a result of their use of inheritance.\n",
    "\n",
    "# Decision 2: Properties vs data classes\n",
    "## Design chosen: Use data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check if we can use decorator pattern to avoid load_pydantic_config_from_file().\n",
    "class StepConfig(BaseSettings):\n",
    "    input_filename: str\n",
    "    output_filename: str\n",
    "    output_train_filename: str\n",
    "    output_val_filename: str\n",
    "    output_test_filename: str\n",
    "    instance_type: str\n",
    "    instance_count: int\n",
    "    step_name: str\n",
    "\n",
    "class ProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    This class provides the schema for the step-specific config file.\n",
    "    It is passed to step factory in the latter's constructor.\n",
    "    \"\"\"\n",
    "    sklearn_framework_version: str\n",
    "    # Override default field with more specific filenames\n",
    "    output_filename: None = None  # type: ignore[assignment]\n",
    "    output_train_filename: str\n",
    "    output_val_filename: str\n",
    "    output_test_filename: str\n",
    "\n",
    "class FrameworkProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    So far no extra configs needed. (While it would be nice if we could set `estimator_cls=SKLearn`\n",
    "    in the config file, but we would have to use `eval()` to construct a python object from the\n",
    "    string, which is a potential security vulnerability.)\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, Type\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Each of the types must be a subclass of StepConfig\n",
    "StepSpecificConfigType = TypeVar(\"StepSpecificConfigType\", bound=BaseSettings)\n",
    "AdditionalConfigType = TypeVar(\"AdditionalConfigType\", bound=BaseSettings)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StepConfigFacade(\n",
    "    Generic[StepSpecificConfigType, AdditionalConfigType]\n",
    "):\n",
    "    # This config type is hard-coded, since it does not depend on step type.\n",
    "    general_step_config: StepConfig\n",
    "    step_specific_config: StepSpecificConfigType\n",
    "    additional_config: AdditionalConfigType\n",
    "\n",
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    FrameworkProcessingConfig,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, if we try to instantiate  a StepConfigFacade with a type variable that is not a subtype of BaseSettings – such as trying to use a dictionary for the AdditionalConfig – the type checker catches this mistake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>1: \u001b[1m\u001b[31merror:\u001b[m Type argument \u001b[m\u001b[1m\"dict[str, str]\"\u001b[m of \u001b[m\u001b[1m\"StepConfigFacade\"\u001b[m must be a subtype of \u001b[m\u001b[1m\"BaseSettings\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n",
      "<cell>1: \u001b[1m\u001b[31merror:\u001b[m Value of type variable \u001b[m\u001b[1m\"AdditionalConfigType\"\u001b[m of \u001b[m\u001b[1m\"StepConfigFacade\"\u001b[m cannot be \u001b[m\u001b[1m\"dict[str, str]\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "FaultyConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    dict[str, str],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23-1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define example configs\n",
    "_step_config = StepConfig(\n",
    "    input_filename='input.parquet',\n",
    "    output_filename='output.parquet',\n",
    "    output_train_filename='output_train.parquet',\n",
    "    output_val_filename='output_val.parquet',\n",
    "    output_test_filename='output_test.parquet',\n",
    "    instance_type='local',\n",
    "    instance_count=1,\n",
    "    step_name='processing',\n",
    ")\n",
    "\n",
    "_processing_config = ProcessingConfig(\n",
    "    sklearn_framework_version='0.23-1',\n",
    "    output_train_filename='output_train.parquet',\n",
    "    output_val_filename='output_val.parquet',\n",
    "    output_test_filename='output_test.parquet',\n",
    ")\n",
    "\n",
    "_framework_processing_config = FrameworkProcessingConfig()\n",
    "\n",
    "fw_proc_configs = FrameworkProcessingConfigFacade(\n",
    "    general_step_config=_step_config,\n",
    "    step_specific_config=_processing_config,\n",
    "    additional_config=_framework_processing_config,\n",
    ")\n",
    "\n",
    "# Access config value\n",
    "fw_proc_configs.step_specific_config.sklearn_framework_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design discarded: use properties\n",
    "This works, but it is simpler to use data classes instead of properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, Type\n",
    "\n",
    "# Each of the types must be a subclass of BaseSettings\n",
    "StepSpecificConfigType = TypeVar(\"StepSpecificConfigType\", bound=BaseSettings)\n",
    "AdditionalConfigType = TypeVar(\"AdditionalConfigType\", bound=BaseSettings)\n",
    "\n",
    "class StepConfigFacade(\n",
    "    Generic[StepSpecificConfigType, AdditionalConfigType]\n",
    "):\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def general_step_config(self) -> StepConfig:\n",
    "        \"\"\"This config type is hard-coded, since it does not depend on step type.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_specific_config(self) -> StepSpecificConfigType:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def additional_config(self) -> AdditionalConfigType:\n",
    "        ...\n",
    "\n",
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    FrameworkProcessingConfig,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with data classes, static analysis catches the error here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>1: \u001b[1m\u001b[31merror:\u001b[m Type argument \u001b[m\u001b[1m\"dict[str, str]\"\u001b[m of \u001b[m\u001b[1m\"StepConfigFacade\"\u001b[m must be a subtype of \u001b[m\u001b[1m\"BaseSettings\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n",
      "<cell>1: \u001b[1m\u001b[31merror:\u001b[m Value of type variable \u001b[m\u001b[1m\"AdditionalConfigType\"\u001b[m of \u001b[m\u001b[1m\"StepConfigFacade\"\u001b[m cannot be \u001b[m\u001b[1m\"dict[str, str]\"\u001b[m  \u001b[m\u001b[33m[type-var]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    dict[str, str],\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
