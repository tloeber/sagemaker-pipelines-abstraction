{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facade + Factory-Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_mypy extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_mypy\n"
     ]
    }
   ],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make imports and folder paths work\n",
    "# todo: Instead create python package and install locally\n",
    "import os, sys\n",
    "os.chdir(\n",
    "    f'{os.environ[\"HOME\"]}/repos/sagemaker-pipelines-abstraction/src'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from functools import cached_property\n",
    "from typing import Literal, Callable, TypeAlias, Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import TypeVar, Generic\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_settings import BaseSettings\n",
    "from loguru import logger\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import Step\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.workflow.steps import ConfigurableRetryStep, ProcessingStep\n",
    "from sm_pipelines_oo.shared_config_schema import Environment\n",
    "\n",
    "from sm_pipelines_oo.shared_config_schema import SharedConfig, Environment\n",
    "# from sm_pipelines_oo.steps.interfaces import StepFactoryInterface\n",
    "from sm_pipelines_oo.connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.utils import load_pydantic_config_from_file\n",
    "from sm_pipelines_oo.connector.interface import AWSConnectorInterface\n",
    "from sm_pipelines_oo.connector.implementation import AWSConnector, LocalAWSConnector, \\\n",
    "    create_aws_connector\n",
    "from sm_pipelines_oo.pipeline_wrapper import PipelineWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "# ==========\n",
    "\n",
    "class StepConfig(BaseSettings):\n",
    "    input_filename: str\n",
    "    output_filename: str\n",
    "    output_train_filename: str\n",
    "    output_val_filename: str\n",
    "    output_test_filename: str\n",
    "    instance_type: str\n",
    "    instance_count: int\n",
    "    step_name: str\n",
    "\n",
    "class ProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    This class provides the schema for the step-specific config file.\n",
    "    It is passed to step factory in the latter's constructor.\n",
    "    \"\"\"\n",
    "    sklearn_framework_version: str\n",
    "    # Override default field with more specific filenames\n",
    "    output_filename: None = None  # type: ignore[assignment]\n",
    "    output_train_filename: str\n",
    "    output_val_filename: str\n",
    "    output_test_filename: str\n",
    "\n",
    "class FrameworkProcessingConfig(BaseSettings):\n",
    "    \"\"\"\n",
    "    So far no extra configs needed. (While it would be nice if we could set `estimator_cls=SKLearn`\n",
    "    in the config file, but we would have to use `eval()` to construct a python object from the\n",
    "    string, which is a potential security vulnerability.)\n",
    "    \"\"\"\n",
    "    estimator_cls: Literal['SKLearn'] = 'SKLearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic StepConfig FACADE\n",
    "# =========================\n",
    "\n",
    "# Each of the types must be a subclass of BaseSettings\n",
    "StepSpecificConfigType = TypeVar(\"StepSpecificConfigType\", bound=BaseSettings)\n",
    "AdditionalConfigType = TypeVar(\"AdditionalConfigType\", bound=BaseSettings)\n",
    "\n",
    "@dataclass\n",
    "class StepConfigFacade(\n",
    "    Generic[StepSpecificConfigType, AdditionalConfigType]\n",
    "):\n",
    "    # This config type is hard-coded, since it does not depend on step type.\n",
    "    general_step_config: StepConfig\n",
    "    step_specific_config: StepSpecificConfigType\n",
    "    additional_config: AdditionalConfigType\n",
    "\n",
    "FrameworkProcessingConfigFacade = StepConfigFacade[\n",
    "    ProcessingConfig,\n",
    "    FrameworkProcessingConfig,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config FACTORY\n",
    "# ===============\n",
    "class ConfigFactoryInterface:\n",
    "    \"\"\"Abstraction layer that allows accessing both shared config and step configs.\"\"\"\n",
    "    @abstractmethod\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> StepConfigFacade:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define example configs\n",
    "_step_config = StepConfig(\n",
    "    input_filename='input.parquet',\n",
    "    output_filename='output.parquet',\n",
    "    output_train_filename='output_train.parquet',\n",
    "    output_val_filename='output_val.parquet',\n",
    "    output_test_filename='output_test.parquet',\n",
    "    instance_type='local',\n",
    "    instance_count=1,\n",
    "    step_name='processing',\n",
    ")\n",
    "\n",
    "_processing_config = ProcessingConfig(\n",
    "    sklearn_framework_version='0.23-1',\n",
    "    output_train_filename='output_train.parquet',\n",
    "    output_val_filename='output_val.parquet',\n",
    "    output_test_filename='output_test.parquet',\n",
    ")\n",
    "\n",
    "_framework_processing_config = FrameworkProcessingConfig(\n",
    "    estimator_cls='SKLearn',\n",
    ")\n",
    "\n",
    "fw_proc_configs = FrameworkProcessingConfigFacade(\n",
    "    general_step_config=_step_config,\n",
    "    step_specific_config=_processing_config,\n",
    "    additional_config=_framework_processing_config,\n",
    ")\n",
    "\n",
    "\n",
    "class MockFWPConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    This class is used to create a mock config for testing purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_step_configs(self, env: Environment, step_name: str) -> FrameworkProcessingConfigFacade:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        if step_name == 'processing':\n",
    "            return fw_proc_configs\n",
    "        else:\n",
    "            raise NotImplementedError(f'No config defined for step {step_name}')\n",
    "\n",
    "    def get_shared_config(self, env: Environment) -> SharedConfig:\n",
    "        if env != 'test':\n",
    "            raise ValueError(f'env must be \"test\", but got {env}')\n",
    "\n",
    "        return SharedConfig(\n",
    "            project_name=\"test\",\n",
    "            project_version='v0.0',\n",
    "            region='us-east-1',\n",
    "            role_name='test_role',\n",
    "            project_bucket_name='test-bucket',\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDefaultConfigFactory\u001b[39;00m(ConfigFactoryInterface):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    The pipeline façade will usually use this class to load configs. Only explicitly specify a\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    different class implementing the same interface for testing purposes (e.g., to directly define\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    config rather than reading from file).\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# todo: Put reading of configs from file, etc, here\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[57], line 8\u001b[0m, in \u001b[0;36mDefaultConfigFactory\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThe pipeline façade will usually use this class to load configs. Only explicitly specify a\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mdifferent class implementing the same interface for testing purposes (e.g., to directly define\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mconfig rather than reading from file).\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# todo: Put reading of configs from file, etc, here\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class DefaultConfigFactory(ConfigFactoryInterface):\n",
    "    \"\"\"\n",
    "    The pipeline façade will usually use this class to load configs. Only explicitly specify a\n",
    "    different class implementing the same interface for testing purposes (e.g., to directly define\n",
    "    config rather than reading from file).\n",
    "    \"\"\"\n",
    "    # todo: Put reading of configs from file, etc, here\n",
    "    raise NotImplementedError # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *General* step FACTORY INTERFACE\n",
    "# ==============================\n",
    "class StepFactoryInterface(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "         self,\n",
    "         shared_config: SharedConfig,\n",
    "         step_configs: StepConfigFacade\n",
    "    ) -> ConfigurableRetryStep:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def step_name(self) -> str:\n",
    "        ...\n",
    "\n",
    "\n",
    "class ProcessingStepFactoryInterface(StepFactoryInterface):\n",
    "    \"\"\"This subclass is distinguished only by more specific return type for step.\"\"\"\n",
    "    @abstractmethod\n",
    "    def create_step(\n",
    "        self,\n",
    "        shared_config: SharedConfig,\n",
    "        step_configs: StepConfigFacade\n",
    "    ) -> ProcessingStep:\n",
    "         ...\n",
    "\n",
    "class FrameworkProcessorFactory(ProcessingStepFactoryInterface):\n",
    "    # todo: Check if there is an inbuilt type for fwp-step.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>32: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"get_mock_fwp_configs\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>44: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"_processor_cls\"\u001b[m; maybe \u001b[m\u001b[1m\"_processor\"\u001b[m?  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>45: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"sklearn_framework_version\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>46: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"instance_type\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>47: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"instance_count\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>48: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingConfig\"\u001b[m has no attribute \u001b[m\u001b[1m\"step_name\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>49: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"aws_connector\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>50: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"aws_connector\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>51: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"_processor_extra_kwargs\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>54: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessorRunArgs\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>55: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"path_factory\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>56: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"path_factory\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>57: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"path_factory\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>59: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessorRunArgs\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>61: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingInput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>67: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingOutput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>72: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingOutput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>77: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingOutput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>83: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"path_factory\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>84: \u001b[1m\u001b[31merror:\u001b[m \u001b[m\u001b[1m\"FrameworkProcessingStepFactory\"\u001b[m has no attribute \u001b[m\u001b[1m\"path_factory\"\u001b[m  \u001b[m\u001b[33m[attr-defined]\u001b[m\n",
      "<cell>90: \u001b[1m\u001b[31merror:\u001b[m Argument 1 of \u001b[m\u001b[1m\"create_step\"\u001b[m is incompatible with supertype \u001b[m\u001b[1m\"ProcessingStepFactoryInterface\"\u001b[m; supertype defines the argument type as \u001b[m\u001b[1m\"SharedConfig\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>90: \u001b[34mnote:\u001b[m This violates the Liskov substitution principle\u001b[m\n",
      "<cell>90: \u001b[34mnote:\u001b[m See \u001b[4mhttps://mypy.readthedocs.io/en/stable/common_issues.html#incompatible-overrides\u001b[m\u001b[m\n",
      "<cell>90: \u001b[1m\u001b[31merror:\u001b[m Argument 1 of \u001b[m\u001b[1m\"create_step\"\u001b[m is incompatible with supertype \u001b[m\u001b[1m\"StepFactoryInterface\"\u001b[m; supertype defines the argument type as \u001b[m\u001b[1m\"SharedConfig\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>90: \u001b[1m\u001b[31merror:\u001b[m Argument 2 of \u001b[m\u001b[1m\"create_step\"\u001b[m is incompatible with supertype \u001b[m\u001b[1m\"ProcessingStepFactoryInterface\"\u001b[m; supertype defines the argument type as \u001b[m\u001b[1m\"StepConfigFacade[Any, Any]\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>90: \u001b[1m\u001b[31merror:\u001b[m Argument 2 of \u001b[m\u001b[1m\"create_step\"\u001b[m is incompatible with supertype \u001b[m\u001b[1m\"StepFactoryInterface\"\u001b[m; supertype defines the argument type as \u001b[m\u001b[1m\"StepConfigFacade[Any, Any]\"\u001b[m  \u001b[m\u001b[33m[override]\u001b[m\n",
      "<cell>95: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>97: \u001b[1m\u001b[31merror:\u001b[m Argument \u001b[m\u001b[1m\"estimator_cls\"\u001b[m to \u001b[m\u001b[1m\"FrameworkProcessor\"\u001b[m has incompatible type \u001b[m\u001b[1m\"StepConfigFacade[ProcessingConfig, FrameworkProcessingConfig]\"\u001b[m; expected \u001b[m\u001b[1m\"type\"\u001b[m  \u001b[m\u001b[33m[arg-type]\u001b[m\n",
      "<cell>98: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>99: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>100: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>101: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>103: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingInput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>104: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>105: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>109: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"ProcessingOutput\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>110: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>111: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n",
      "<cell>114: \u001b[1m\u001b[31merror:\u001b[m Name \u001b[m\u001b[1m\"step_config\"\u001b[m is not defined  \u001b[m\u001b[33m[name-defined]\u001b[m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step Factory IMPLEMENTATION\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ===========================\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFrameworkProcessingStepFactory\u001b[39;00m(ProcessingStepFactoryInterface):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    shared config etc will be passed during create_step().\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m         step_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     12\u001b[0m     ):\n",
      "Cell \u001b[0;32mIn[51], line 36\u001b[0m, in \u001b[0;36mFrameworkProcessingStepFactory\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_mock_fwp_configs()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# todo: Generalize types to other processors\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_processor\u001b[39m(\u001b[38;5;28mself\u001b[39m, step_configs: FrameworkProcessingConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mProcessor\u001b[49m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    Instantiate processor, combining step-specific configs with configs from AWS connector.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    a separate method that accepts outside configs as arguments, if necessary in the future.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processor_cls(\n\u001b[1;32m     45\u001b[0m         framework_version\u001b[38;5;241m=\u001b[39mstep_configs\u001b[38;5;241m.\u001b[39msklearn_framework_version,\n\u001b[1;32m     46\u001b[0m         instance_type\u001b[38;5;241m=\u001b[39mstep_configs\u001b[38;5;241m.\u001b[39minstance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processor_extra_kwargs,\n\u001b[1;32m     52\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Processor' is not defined"
     ]
    }
   ],
   "source": [
    "# Step Factory IMPLEMENTATION\n",
    "# ===========================\n",
    "\n",
    "class FrameworkProcessingStepFactory(ProcessingStepFactoryInterface):\n",
    "    \"\"\"\n",
    "    shared config etc will be passed during create_step().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        step_name: str,\n",
    "    ):\n",
    "        self._step_name = step_name\n",
    "\n",
    "        # This determines how to construct the estimator object from the string in the config file, avoiding the\n",
    "        # use of `eval`, which is a potential security vulnerability.\n",
    "        self._str_to_cls_mapping: dict[str, Any] = {  # todo:  find supertype\n",
    "            'SKLearn': SKLearn,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def step_name(self) -> str:\n",
    "        return self._step_name\n",
    "\n",
    "    def support_additional_estimators(self, additional_estimator_mapping: dict[str, Any]) -> None:\n",
    "        \"\"\"Allow user to add additional estimators (following the open-closed principle).\"\"\"\n",
    "        self._str_to_cls_mapping.update(additional_estimator_mapping)\n",
    "\n",
    "    def _construct_step_configs(self, env: Environment, step_name: str) -> FrameworkProcessingConfigFacade:\n",
    "        \"\"\"Load configs from file and return them as a single wrapper object.\"\"\"\n",
    "        # todo: use composition, e.g. configfactory, to ensure testability w/o mocking\n",
    "        return get_mock_fwp_configs()\n",
    "\n",
    "\n",
    "    # todo: Generalize types to other processors\n",
    "    def _processor(self, step_configs: FrameworkProcessingConfig) -> Processor:  # type: ignore\n",
    "        \"\"\"\n",
    "        Instantiate processor, combining step-specific configs with configs from AWS connector.\n",
    "\n",
    "        Note that we could technically run this in __init__() now, because we do no longer use\n",
    "        anything from the shared_config. However, leaving it here keeps the option open to make it\n",
    "        a separate method that accepts outside configs as arguments, if necessary in the future.\n",
    "        \"\"\"\n",
    "        return self._processor_cls(\n",
    "            framework_version=step_configs.sklearn_framework_version,\n",
    "            instance_type=step_configs.instance_type,\n",
    "            instance_count=step_configs.instance_count,\n",
    "            base_job_name=step_configs.step_name,\n",
    "            sagemaker_session=self.aws_connector.sm_session,\n",
    "            role=self.aws_connector.role_arn,\n",
    "            **self._processor_extra_kwargs,\n",
    "        )  # type: ignore\n",
    "\n",
    "    def _get_processor_run_args(self) -> ProcessorRunArgs:\n",
    "        s3_input_folder: str = self.path_factory.s3_input_folder\n",
    "        s3_output_folder: str = self.path_factory.s3_output_folder\n",
    "        local_folderpath: str = self.path_factory.local_folderpath\n",
    "\n",
    "        skl_run_args = ProcessorRunArgs(\n",
    "            inputs = [\n",
    "                ProcessingInput(\n",
    "                    source=s3_input_folder,\n",
    "                    destination=f\"{local_folderpath}/input/\"\n",
    "                ),\n",
    "            ],\n",
    "            outputs = [\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"train\",\n",
    "                    source=f\"/{local_folderpath}/train\",\n",
    "                    destination=f\"{s3_output_folder}/train\",\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"validation\",\n",
    "                    source=f\"/{local_folderpath}/validation\",\n",
    "                    destination=f\"{s3_output_folder}/validation\",\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"test\",\n",
    "                    source=f\"/{local_folderpath}/test\",\n",
    "                    destination=f\"{s3_output_folder}/test\",\n",
    "                ),\n",
    "            ],\n",
    "            source_dir=self.path_factory.source_dir,\n",
    "            code=self.path_factory.step_code_file,\n",
    "            arguments=None # Todo: Decide whether this should come from configuration. May depend on type of step.\n",
    "        )\n",
    "        return skl_run_args\n",
    "\n",
    "    # todo: Add more specific return type (may have to create custom type, but check Sagemaker sdk code again)\n",
    "    def create_step(self, env: Environment, shared_config: SharedConfig) -> ProcessingStep:\n",
    "        # todo: think about how to create these here\n",
    "        step_configs = fw_proc_configs\n",
    "\n",
    "        return ProcessingStep(\n",
    "            name=step_config.step_name,\n",
    "            processor=FrameworkProcessor(\n",
    "                estimator_cls=step_configs,\n",
    "                framework_version=step_config.sklearn_framework_version,\n",
    "                instance_type=step_config.instance_type,\n",
    "                instance_count=step_config.instance_count,\n",
    "                role=step_config.role_name,\n",
    "            ),\n",
    "            inputs=[ProcessingInput(\n",
    "                source=step_config.input_data,\n",
    "                destination=step_config.output_data,\n",
    "                s3_data_type='S3Prefix',\n",
    "                s3_input_mode='File',\n",
    "            )],\n",
    "            outputs=[ProcessingOutput(\n",
    "                source=step_config.output_data,\n",
    "                destination=step_config.output_data,\n",
    "                s3_upload_mode='EndOfJob',\n",
    "            )],\n",
    "            code=step_config.code,\n",
    "        )\n",
    "fw_proc_step_factory = FrameworkProcessingStepFactory(step_name='preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline facade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<cell>16: \u001b[1m\u001b[31merror:\u001b[m Cannot instantiate abstract class \u001b[m\u001b[1m\"DefaultConfigFactory\"\u001b[m with abstract attributes \u001b[m\u001b[1m\"get_shared_config\"\u001b[m and \u001b[m\u001b[1m\"get_step_configs\"\u001b[m  \u001b[m\u001b[33m[abstract]\u001b[m\n"
     ]
    }
   ],
   "source": [
    "class PipelineFacade:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Each step factory is instantiated with its step_name, thus identifying step_config\n",
    "        step_factories: list[StepFactoryInterface],\n",
    "        env: Environment,\n",
    "        config_factory: ConfigFactoryInterface | None,\n",
    "    ) -> None:\n",
    "        self._env: Environment = env\n",
    "        self._step_factories = step_factories\n",
    "\n",
    "        # Generally, we can simply use the default StepConfigFactory.\n",
    "        # However, we want to be able to pass a custom factory for testing purposes.\n",
    "        self._config_factory: ConfigFactoryInterface = (\n",
    "            config_factory if config_factory is not None\n",
    "                else DefaultConfigFactory()  # type: ignore\n",
    "        )\n",
    "                # Now that we know config factory is defined, we can use it to load shared config\n",
    "        self._shared_config: SharedConfig = self._config_factory.get_shared_config(\n",
    "            env=self._env\n",
    "        )\n",
    "\n",
    "    @cached_property\n",
    "    def _steps(self) -> list[Step]:\n",
    "        steps: list[Step] = []\n",
    "        for step_factory in self._step_factories:\n",
    "            step_configs: StepConfigFacade = self._config_factory.get_step_configs(\n",
    "                env=self._env,\n",
    "                step_name=step_factory.step_name,\n",
    "            )\n",
    "            step: Step = step_factory.create_step(\n",
    "                shared_config=self._shared_config,\n",
    "                step_configs=step_configs,\n",
    "            )\n",
    "            steps.append(step)\n",
    "        return steps\n",
    "\n",
    "    @cached_property\n",
    "    def _aws_connector(self) -> AWSConnectorInterface:\n",
    "        \"\"\"\n",
    "        This code makes connector.implementation.create_aws_connector() redundant, except for use\n",
    "        outside of pipeline.\n",
    "        Todo: decide where to put code for the latter case.\n",
    "        \"\"\"\n",
    "        # todo: make this a factory, and move it out of facade?\n",
    "        if self._env == 'local':\n",
    "            return LocalAWSConnector()\n",
    "        else:\n",
    "            return AWSConnector(\n",
    "                environment=self._env,\n",
    "                # this error will resolve once we don't use SharedConfig from this notebook but\n",
    "                # library's AWSConnector.\n",
    "                shared_config=self._shared_config,  # type: ignore\n",
    "                run_as_pipeline=True\n",
    "            )\n",
    "\n",
    "    @cached_property\n",
    "    def _pipeline(self) -> Pipeline:\n",
    "        \"\"\"\n",
    "        We could make this a private  method and call it in __init__(), but this is shorter.\n",
    "        \"\"\"\n",
    "        pipeline_name = f'{self._shared_config.project_name}-{datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "        pipeline = Pipeline(\n",
    "            name=pipeline_name,\n",
    "            steps=self._steps,\n",
    "            sagemaker_session=self._aws_connector.sm_session,\n",
    "        )\n",
    "        pipeline.create(role_arn=self._aws_connector.role_arn)\n",
    "        return pipeline\n",
    "\n",
    "    def run(self) -> None:\n",
    "        try:\n",
    "            logger.info(f\"Starting pipeline run for project {self._shared_config.project_name}\")\n",
    "            execution = self._pipeline.start()\n",
    "            execution.wait()\n",
    "            execution.list_steps()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fw_proc_step_factory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline\u001b[38;5;241m=\u001b[39m PipelineFacade(\n\u001b[0;32m----> 2\u001b[0m     step_factories\u001b[38;5;241m=\u001b[39m[\u001b[43mfw_proc_step_factory\u001b[49m],\n\u001b[1;32m      3\u001b[0m     env\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     config_factory\u001b[38;5;241m=\u001b[39mMockFWPConfigFactory(),\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fw_proc_step_factory' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline= PipelineFacade(\n",
    "    step_factories=[fw_proc_step_factory],\n",
    "    env='local',\n",
    "    config_factory=MockFWPConfigFactory(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm-pipelines-oo-tWfBw0_D-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
